{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d76d966a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import datasets\n",
    "from functools import partial\n",
    "\n",
    "# Add the project root directory to the Python path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '../..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from src.utils.dataset_tokenization import process_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5031838c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73d6b7a40c9e4b73b9d62977e1460dcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelfCorrectiveLlama(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(128256, 2048)\n",
      "    (layers): ModuleList(\n",
      "      (0-15): 16 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
      "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
      "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
      "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
      "  (new_token_embeddings): Embedding(3, 2048)\n",
      "  (hallucination_gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
      "  (hallucination_up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
      "  (hallucination_down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
      "  (hallucination_detector): Linear(in_features=2048, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_path = \"../../self-corrective-llama_untrained\"\n",
    "# model_name = \"MathBite/self_corrective_llama_3.1_8B_untrained\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, trust_remote_code=True)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8bbcea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPECIAL_INSTRUCTION = \"\\nAs you write your answer, you can correct yourself using these tools: Use <DEL_W> to take back the word before this token, <DEL_S> to remove the entire sentence before this token, and <DEL_A> to scrap everything you've written and start again.\"\n",
    "# INSERTION_MARKER = \"<|start_header_id|>user<|end_header_id|>\"\n",
    "# DELETION_MARKERS = [\"<DEL_W>\", \"<DEL_S>\", \"<DEL_A>\"]\n",
    "# DELETION_TOKEN_IDS = tokenizer.convert_tokens_to_ids(DELETION_MARKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f473c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = \"../../dataset/train.json\"\n",
    "# dataset = datasets.load_dataset(\"json\", data_files=data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f4f05f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ef0a0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = dataset[\"train\"][7295]\n",
    "# print(sample)\n",
    "# print(sample[\"correct_response\"])\n",
    "# print(sample[\"errors\"])\n",
    "# print(sample[\"hallucinated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d595220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(7295, 7296):\n",
    "#     sample = dataset[\"train\"][i]\n",
    "    \n",
    "#     res = process_data(sample, tokenizer, SPECIAL_INSTRUCTION, INSERTION_MARKER, DELETION_TOKEN_IDS[0], DELETION_TOKEN_IDS[1], DELETION_TOKEN_IDS[2])\n",
    "\n",
    "#     hall_text_idx = [i for i, label in enumerate(res[\"hallucination_labels\"]) if label == 1]\n",
    "#     hall_text = [res[\"input_ids\"][i] for i in hall_text_idx]\n",
    "    \n",
    "#     print(sample[\"correct_response\"])\n",
    "#     print(\"================================================\")\n",
    "#     for error in sample[\"hallucinated_text\"]:\n",
    "#         print(error)\n",
    "#     print(\"================================================\")\n",
    "#     print(tokenizer.decode(hall_text))\n",
    "#     print(\"--------------------------------\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23d4948f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPECIAL_INSTRUCTION = \"\\nAs you write your answer, you can correct yourself using these tools: Use <DEL_W> to take back the word before this token, <DEL_S> to remove the entire sentence before this token, and <DEL_A> to scrap everything you've written and start again.\"\n",
    "# INSERTION_MARKER = \"<|start_header_id|>user<|end_header_id|>\"\n",
    "# DELETION_MARKERS = [\"<DEL_W>\", \"<DEL_S>\", \"<DEL_A>\"]\n",
    "# DELETION_TOKEN_IDS = tokenizer.convert_tokens_to_ids(DELETION_MARKERS)\n",
    "\n",
    "# mapper = partial(\n",
    "#     process_data,\n",
    "#     tokenizer=tokenizer,\n",
    "#     special_instruction=SPECIAL_INSTRUCTION,\n",
    "#     insertion_marker=INSERTION_MARKER,\n",
    "#     del_w_token_id=DELETION_TOKEN_IDS[0],\n",
    "#     del_s_token_id=DELETION_TOKEN_IDS[1],\n",
    "#     del_a_token_id=DELETION_TOKEN_IDS[2]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a39d7544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.cleanup_cache_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab5444da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_dataset = dataset.map(mapper, batched=False, load_from_cache_file=False)\n",
    "# tokenized_dataset = tokenized_dataset[\"train\"]\n",
    "# columns_to_remove = [\n",
    "#     \"input\", \"correct_response\", \"incorrect_response\", \n",
    "#     \"additional_info\", \"errors\", \"hallucinated_text\"\n",
    "# ]\n",
    "\n",
    "# tokenized_dataset = tokenized_dataset.remove_columns(columns_to_remove)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d3da683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ef1e043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_dataset = tokenized_dataset.train_test_split(test_size=0.1, seed=42)\n",
    "# print(split_dataset)\n",
    "# train_dataset = split_dataset['train']\n",
    "# eval_dataset = split_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1652a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_dir = \"../../dataset/training\"\n",
    "# split_dataset.save_to_disk(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a0a7360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels', 'hallucination_labels'],\n",
      "    num_rows: 36684\n",
      "})\n",
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels', 'hallucination_labels'],\n",
      "    num_rows: 4077\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.load_from_disk(\"../../dataset/training\")\n",
    "train_dataset = dataset[\"train\"]\n",
    "eval_dataset = dataset[\"test\"]\n",
    "\n",
    "print(train_dataset)\n",
    "print(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a681e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356.67721622505724\n"
     ]
    }
   ],
   "source": [
    "# max_len = 0\n",
    "# max_len_id = 0\n",
    "# for i in range(0, len(train_dataset)):\n",
    "#     sample = train_dataset[i]\n",
    "#     if len(sample[\"input_ids\"]) > max_len:\n",
    "#         max_len = len(sample[\"input_ids\"])\n",
    "#         max_len_id = i\n",
    "\n",
    "# print(max_len)\n",
    "# print(max_len_id)\n",
    "\n",
    "\n",
    "avg_len = 0\n",
    "for i in range(0, len(train_dataset)):\n",
    "    sample = train_dataset[i]\n",
    "    avg_len += len(sample[\"input_ids\"])\n",
    "\n",
    "print(avg_len / len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e33851ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282\n",
      "257\n",
      "355\n",
      "300\n",
      "535\n",
      "397\n",
      "175\n",
      "322\n",
      "339\n",
      "296\n",
      "326\n",
      "444\n",
      "748\n",
      "791\n",
      "322\n",
      "227\n",
      "273\n",
      "304\n",
      "416\n",
      "283\n",
      "436\n",
      "491\n",
      "455\n",
      "283\n",
      "386\n",
      "239\n",
      "292\n",
      "678\n",
      "328\n",
      "251\n",
      "266\n",
      "368\n",
      "284\n",
      "280\n",
      "431\n",
      "694\n",
      "379\n",
      "289\n",
      "380\n",
      "562\n",
      "274\n",
      "504\n",
      "193\n",
      "534\n",
      "277\n",
      "302\n",
      "627\n",
      "418\n",
      "341\n",
      "614\n",
      "287\n",
      "201\n",
      "229\n",
      "288\n",
      "265\n",
      "240\n",
      "595\n",
      "266\n",
      "279\n",
      "326\n",
      "392\n",
      "660\n",
      "330\n",
      "339\n",
      "419\n",
      "371\n",
      "175\n",
      "397\n",
      "282\n",
      "261\n",
      "341\n",
      "352\n",
      "275\n",
      "543\n",
      "365\n",
      "454\n",
      "327\n",
      "574\n",
      "587\n",
      "430\n",
      "351\n",
      "406\n",
      "295\n",
      "395\n",
      "281\n",
      "383\n",
      "242\n",
      "501\n",
      "321\n",
      "826\n",
      "229\n",
      "378\n",
      "277\n",
      "523\n",
      "347\n",
      "555\n",
      "302\n",
      "487\n",
      "328\n",
      "270\n",
      "235\n",
      "383\n",
      "344\n",
      "283\n",
      "264\n",
      "250\n",
      "346\n",
      "262\n",
      "267\n",
      "385\n",
      "434\n",
      "288\n",
      "467\n",
      "551\n",
      "520\n",
      "339\n",
      "464\n",
      "260\n",
      "167\n",
      "425\n",
      "297\n",
      "569\n",
      "453\n",
      "325\n",
      "473\n",
      "436\n",
      "219\n",
      "657\n",
      "345\n",
      "520\n",
      "229\n",
      "350\n",
      "247\n",
      "363\n",
      "419\n",
      "551\n",
      "316\n",
      "293\n",
      "301\n",
      "509\n",
      "295\n",
      "519\n",
      "826\n",
      "238\n",
      "281\n",
      "296\n",
      "354\n",
      "511\n",
      "532\n",
      "340\n",
      "202\n",
      "283\n",
      "314\n",
      "362\n",
      "311\n",
      "312\n",
      "393\n",
      "309\n",
      "367\n",
      "301\n",
      "279\n",
      "386\n",
      "264\n",
      "371\n",
      "414\n",
      "310\n",
      "481\n",
      "311\n",
      "361\n",
      "275\n",
      "243\n",
      "242\n",
      "412\n",
      "280\n",
      "534\n",
      "297\n",
      "541\n",
      "412\n",
      "398\n",
      "438\n",
      "319\n",
      "323\n",
      "269\n",
      "341\n",
      "402\n",
      "248\n",
      "421\n",
      "585\n",
      "353\n",
      "465\n",
      "276\n",
      "678\n",
      "207\n",
      "187\n",
      "175\n",
      "366\n",
      "175\n",
      "270\n",
      "285\n",
      "398\n",
      "339\n",
      "265\n",
      "307\n",
      "989\n",
      "411\n",
      "320\n",
      "366\n",
      "300\n",
      "369\n",
      "193\n",
      "577\n",
      "498\n",
      "356\n",
      "603\n",
      "453\n",
      "248\n",
      "522\n",
      "281\n",
      "378\n",
      "466\n",
      "310\n",
      "246\n",
      "382\n",
      "278\n",
      "260\n",
      "672\n",
      "406\n",
      "339\n",
      "476\n",
      "423\n",
      "314\n",
      "329\n",
      "381\n",
      "357\n",
      "675\n",
      "532\n",
      "330\n",
      "804\n",
      "241\n",
      "332\n",
      "303\n",
      "322\n",
      "388\n",
      "256\n",
      "457\n",
      "305\n",
      "264\n",
      "334\n",
      "255\n",
      "331\n",
      "313\n",
      "267\n",
      "376\n",
      "271\n",
      "525\n",
      "335\n",
      "787\n",
      "330\n",
      "315\n",
      "584\n",
      "271\n",
      "367\n",
      "379\n",
      "401\n",
      "357\n",
      "331\n",
      "273\n",
      "361\n",
      "348\n",
      "218\n",
      "277\n",
      "493\n",
      "282\n",
      "506\n",
      "227\n",
      "275\n",
      "286\n",
      "324\n",
      "538\n",
      "333\n",
      "298\n",
      "245\n",
      "320\n",
      "288\n",
      "293\n",
      "264\n",
      "315\n",
      "362\n",
      "252\n",
      "417\n",
      "522\n",
      "272\n",
      "316\n",
      "301\n",
      "563\n",
      "355\n",
      "338\n",
      "346\n",
      "417\n",
      "511\n",
      "296\n",
      "313\n",
      "257\n",
      "277\n",
      "285\n",
      "372\n",
      "310\n",
      "380\n",
      "343\n",
      "281\n",
      "335\n",
      "431\n",
      "303\n",
      "345\n",
      "265\n",
      "503\n",
      "398\n",
      "323\n",
      "388\n",
      "282\n",
      "323\n",
      "343\n",
      "454\n",
      "261\n",
      "242\n",
      "316\n",
      "328\n",
      "371\n",
      "405\n",
      "283\n",
      "297\n",
      "385\n",
      "291\n",
      "274\n",
      "253\n",
      "308\n",
      "263\n",
      "564\n",
      "730\n",
      "263\n",
      "864\n",
      "442\n",
      "377\n",
      "295\n",
      "287\n",
      "760\n",
      "628\n",
      "466\n",
      "300\n",
      "298\n",
      "783\n",
      "294\n",
      "434\n",
      "275\n",
      "346\n",
      "337\n",
      "522\n",
      "370\n",
      "394\n",
      "256\n",
      "275\n",
      "600\n",
      "314\n",
      "325\n",
      "303\n",
      "267\n",
      "245\n",
      "264\n",
      "251\n",
      "513\n",
      "317\n",
      "460\n",
      "243\n",
      "538\n",
      "439\n",
      "317\n",
      "381\n",
      "308\n",
      "551\n",
      "245\n",
      "357\n",
      "283\n",
      "437\n",
      "382\n",
      "321\n",
      "185\n",
      "267\n",
      "210\n",
      "479\n",
      "450\n",
      "303\n",
      "279\n",
      "239\n",
      "658\n",
      "393\n",
      "368\n",
      "352\n",
      "405\n",
      "240\n",
      "292\n",
      "390\n",
      "376\n",
      "533\n",
      "225\n",
      "259\n",
      "297\n",
      "366\n",
      "337\n",
      "338\n",
      "435\n",
      "242\n",
      "396\n",
      "179\n",
      "403\n",
      "811\n",
      "360\n",
      "304\n",
      "297\n",
      "281\n",
      "705\n",
      "361\n",
      "441\n",
      "301\n",
      "226\n",
      "243\n",
      "462\n",
      "263\n",
      "312\n",
      "319\n",
      "570\n",
      "277\n",
      "335\n",
      "586\n",
      "295\n",
      "298\n",
      "376\n",
      "367\n",
      "272\n",
      "385\n",
      "451\n",
      "236\n",
      "273\n",
      "279\n",
      "344\n",
      "403\n",
      "263\n",
      "304\n",
      "290\n",
      "316\n",
      "217\n",
      "326\n",
      "342\n",
      "277\n",
      "327\n",
      "268\n",
      "426\n",
      "242\n",
      "399\n",
      "825\n",
      "274\n",
      "325\n",
      "350\n",
      "389\n",
      "210\n",
      "431\n",
      "237\n",
      "249\n",
      "632\n",
      "311\n",
      "354\n",
      "276\n",
      "382\n",
      "258\n",
      "290\n",
      "465\n",
      "398\n",
      "352\n",
      "217\n",
      "392\n",
      "258\n",
      "221\n",
      "369\n",
      "267\n",
      "280\n",
      "669\n",
      "491\n",
      "305\n",
      "284\n",
      "210\n",
      "247\n",
      "385\n",
      "313\n",
      "574\n",
      "335\n",
      "306\n",
      "289\n",
      "861\n",
      "355\n",
      "259\n",
      "953\n",
      "225\n",
      "329\n",
      "298\n",
      "367\n",
      "284\n",
      "272\n",
      "330\n",
      "287\n",
      "495\n",
      "380\n",
      "213\n",
      "305\n",
      "254\n",
      "462\n",
      "427\n",
      "329\n",
      "256\n",
      "319\n",
      "506\n",
      "258\n",
      "336\n",
      "327\n",
      "350\n",
      "257\n",
      "313\n",
      "532\n",
      "310\n",
      "337\n",
      "358\n",
      "338\n",
      "231\n",
      "658\n",
      "315\n",
      "208\n",
      "213\n",
      "270\n",
      "333\n",
      "447\n",
      "375\n",
      "346\n",
      "239\n",
      "424\n",
      "287\n",
      "722\n",
      "386\n",
      "285\n",
      "640\n",
      "462\n",
      "310\n",
      "267\n",
      "295\n",
      "327\n",
      "412\n",
      "706\n",
      "459\n",
      "297\n",
      "430\n",
      "208\n",
      "204\n",
      "277\n",
      "574\n",
      "885\n",
      "398\n",
      "655\n",
      "297\n",
      "507\n",
      "431\n",
      "264\n",
      "474\n",
      "280\n",
      "503\n",
      "310\n",
      "282\n",
      "263\n",
      "293\n",
      "265\n",
      "217\n",
      "358\n",
      "268\n",
      "343\n",
      "416\n",
      "348\n",
      "249\n",
      "418\n",
      "398\n",
      "173\n",
      "270\n",
      "427\n",
      "284\n",
      "380\n",
      "290\n",
      "372\n",
      "253\n",
      "316\n",
      "173\n",
      "330\n",
      "446\n",
      "234\n",
      "258\n",
      "299\n"
     ]
    }
   ],
   "source": [
    "# for i in range(4000, 4600):\n",
    "#     print(len(train_dataset[i][\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67239ce5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ce570d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dd1ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = train_dataset[5]\n",
    "# sample[\"input_ids\"] = torch.tensor(sample[\"input_ids\"]).reshape(1, -1)\n",
    "# sample[\"hallucination_labels\"] = torch.tensor(sample[\"hallucination_labels\"]).reshape(1, -1)\n",
    "# sample[\"labels\"] = torch.tensor(sample[\"labels\"]).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac5a0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa145245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(sample[\"labels\"][sample[\"labels\"] != -100])\n",
    "# print(sample[\"hallucination_labels\"][sample[\"hallucination_labels\"] != -100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef4db77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.forward(\n",
    "#     input_ids = sample[\"input_ids\"],\n",
    "#     hallucination_labels = sample[\"hallucination_labels\"],\n",
    "#     labels = sample[\"labels\"]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7b4236",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b1ff83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7604931c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del_tokens = [\"<DEL_W>\", \"<DEL_S>\", \"<DEL_A>\"]\n",
    "\n",
    "\n",
    "# for i in range(100, 200):\n",
    "#     sample = train_dataset[i]\n",
    "#     print(tokenizer.decode(sample[\"input_ids\"]), \"\\n\")\n",
    "\n",
    "#     for j in range(1, 4):\n",
    "#         hall_text_idx = [i for i, label in enumerate(sample[\"hallucination_labels\"]) if label == j]\n",
    "#         hall_text = [sample[\"input_ids\"][i] for i in hall_text_idx]\n",
    "\n",
    "#         print(\"--------------------------------\\n\")\n",
    "#         print(f\"Deletion token: {del_tokens[j-1]}\")\n",
    "#         print(tokenizer.decode(hall_text))\n",
    "        \n",
    "    \n",
    "#     print(\"########################################################\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39e9fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517ae0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import (\n",
    "#     AutoTokenizer,\n",
    "#     AutoModelForCausalLM,\n",
    "#     TrainingArguments,\n",
    "#     BitsAndBytesConfig,\n",
    "# )\n",
    "# import torch\n",
    "# from src.trainer import SelfCorrectionTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10db52ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = SelfCorrectionTrainer(model = \"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501b545c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = train_dataset[0]\n",
    "# sample[\"input_ids\"] = torch.tensor(sample[\"input_ids\"]).reshape(1, -1)\n",
    "# sample[\"hallucination_labels\"] = torch.tensor(sample[\"hallucination_labels\"]).reshape(1, -1)\n",
    "# sample[\"labels\"] = torch.tensor(sample[\"labels\"]).reshape(1, -1)\n",
    "# print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac8a237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = sample.copy()\n",
    "# # output[\"logits\"] = torch.tensor(output[\"input_ids\"]).reshape(1, -1, 1)\n",
    "# output[\"logits\"] = torch.zeros(1, output[\"input_ids\"].shape[-1], len(tokenizer.get_vocab())) - 100\n",
    "# for i in range(output[\"input_ids\"].shape[-1]):\n",
    "#     output[\"logits\"][0, i, output[\"input_ids\"][0, i]] = 100\n",
    "# output[\"hallucination_logits\"] = torch.tensor(output[\"hallucination_labels\"]).reshape(1, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d251c427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output[\"logits\"][0, :-1, ...] = output[\"logits\"].clone()[0, 1:, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2795b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.compute_loss(sample, output, len(tokenizer.get_vocab()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcd6ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb49a3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# logits = torch.zeros(1, 10, 100)\n",
    "# hallucination_logits = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]).reshape(1, 10, 1)\n",
    "\n",
    "# additional_logits = torch.zeros_like(logits)\n",
    "# additional_logits[:, :, -3:] = hallucination_logits\n",
    "# logits = logits + additional_logits\n",
    "# print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bbe3ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302c8dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B-Instruct\")\n",
    "# base_model = AutoModelForCausalLM.from_pretrained(\n",
    "#     \"meta-llama/Llama-3.2-1B-Instruct\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd1c00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(base_model.lm_head.weight.shape)\n",
    "# print(base_model.lm_head.weight[-5:, :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47558c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model.resize_token_embeddings(len(tokenizer.get_vocab())+3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79e23bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(base_model.lm_head.weight.shape)\n",
    "# print(base_model.lm_head.weight[-8:, :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4697bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "# import os\n",
    "# import sys\n",
    "# import torch\n",
    "\n",
    "# # Add the project root directory to the Python path\n",
    "# project_root = os.path.abspath(os.path.join(os.getcwd(), '../..'))\n",
    "# if project_root not in sys.path:\n",
    "#     sys.path.insert(0, project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd72f131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"../../self-corrective-llama_untrained\"\n",
    "# # path = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(path)\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "# model = AutoModelForCausalLM.from_pretrained(path, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab96102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelfCorrectiveLlama(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0-15): 16 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
       "  (new_token_embeddings): Embedding(3, 2048)\n",
       "  (hallucination_gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "  (hallucination_up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "  (hallucination_down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "  (hallucination_detector): Linear(in_features=2048, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef85f8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text: <|begin_of_text|>What is the capital of France? Paris.\n",
      "The capital of France is Paris. Paris is the most populous city in France and is known for its rich history, art, fashion, and cuisine. It is also home to many famous landmarks such as the Eiffel Tower, Notre Dame\n",
      "Hallucination Logits Shape: torch.Size([1, 50, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def generate_with_hallucination_analysis(model, tokenizer, prompt_text, max_new_tokens=50):\n",
    "    \"\"\"\n",
    "    Generates text and then runs a second pass to get hallucination logits\n",
    "    for the generated tokens, avoiding interference with the generate loop.\n",
    "    \"\"\"\n",
    "    # Ensure the model is in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # --- Pass 1: Generate the text ---\n",
    "    # We use the standard, unmodified generate method.\n",
    "    inputs = tokenizer(prompt_text, return_tensors=\"pt\").to(model.device)\n",
    "    generated_ids = model.generate(**inputs, max_new_tokens=max_new_tokens)\n",
    "    \n",
    "    # Decode the full generated text\n",
    "    generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=False)\n",
    "    \n",
    "    # --- Pass 2: Run a single forward pass on the full sequence to get all logits ---\n",
    "    # This is more efficient than collecting them step-by-step.\n",
    "    with torch.no_grad():\n",
    "        full_sequence_outputs = model(generated_ids)\n",
    "    \n",
    "    # Extract the hallucination logits from the output\n",
    "    hallucination_logits = full_sequence_outputs.hallucination_logits\n",
    "    \n",
    "    # We only care about the logits for the *newly generated* tokens.\n",
    "    # The logit at position `i` is the prediction for the token at `i+1`.\n",
    "    prompt_len = inputs.input_ids.shape[1]\n",
    "    generated_hallucination_logits = hallucination_logits[:, prompt_len-1:-1, :]\n",
    "    \n",
    "    return generated_text, generated_hallucination_logits\n",
    "\n",
    "# --- Example Usage ---\n",
    "text, hall_logits = generate_with_hallucination_analysis(\n",
    "    model, \n",
    "    tokenizer, \n",
    "    \"What is the capital of France?\",\n",
    "    max_new_tokens=50\n",
    ")\n",
    "print(\"Generated Text:\", text)\n",
    "print(\"Hallucination Logits Shape:\", hall_logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf4ba56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0483, -0.2782, -0.0229,  0.5821],\n",
       "         [-0.0457, -0.1654,  0.4881,  0.7241],\n",
       "         [ 0.1563, -0.2808,  0.1752, -0.0528],\n",
       "         [ 0.6500, -0.0672,  0.0963,  0.3451],\n",
       "         [-0.1016,  0.2346,  0.2451,  0.1382],\n",
       "         [ 0.2472, -0.1517,  0.0213,  0.0206],\n",
       "         [ 0.3422, -0.2132,  0.6742,  0.3600],\n",
       "         [ 0.1035,  0.4354, -0.0361,  0.1883],\n",
       "         [-0.1177, -0.2437,  0.4974,  0.3574],\n",
       "         [ 0.2063, -0.2982,  0.4049,  0.0723],\n",
       "         [ 0.2247, -0.1464,  0.2873,  1.2442],\n",
       "         [-0.0031,  0.1955, -0.2148,  0.1981],\n",
       "         [ 0.0102, -0.1352,  0.1593, -0.2428],\n",
       "         [ 0.0284,  0.3141,  0.6227,  0.0378],\n",
       "         [-0.1079,  0.2176,  0.2375, -0.3359],\n",
       "         [-0.2790, -0.0070, -0.1074, -0.0306],\n",
       "         [-0.0129, -0.8086, -0.1504,  0.3837],\n",
       "         [-0.1234,  0.0691,  0.0285,  0.2415],\n",
       "         [-0.0553, -0.1397,  0.1646,  0.7801],\n",
       "         [-0.1584,  0.2697,  0.0933,  0.1162],\n",
       "         [-0.4042,  0.0693, -0.1235,  0.5240],\n",
       "         [-0.0888, -0.0914, -0.4243,  0.5295],\n",
       "         [ 0.1963, -0.0890, -0.4105,  0.5588],\n",
       "         [ 0.0786, -0.1023,  0.1575,  0.2961],\n",
       "         [-0.1572,  0.3389,  0.0983,  0.1115],\n",
       "         [ 0.0387,  0.3779, -0.2758,  0.7401],\n",
       "         [-0.5264, -0.1391,  0.2975,  0.2731],\n",
       "         [-0.1892, -0.0156,  0.3868,  0.1051],\n",
       "         [-0.2313, -0.4502,  0.0030, -0.3661],\n",
       "         [-0.1219,  0.0046,  0.0935,  0.1354],\n",
       "         [-0.6679,  0.5465, -0.1752,  0.0066],\n",
       "         [-0.1049, -0.2908,  0.4107,  0.3828],\n",
       "         [-0.0455, -0.3115,  0.2520,  0.1193],\n",
       "         [-0.2105,  0.0993, -0.0175,  0.8026],\n",
       "         [-0.0024,  0.0715,  0.2570,  0.1972],\n",
       "         [-0.1381, -0.1505,  0.3845,  0.2334],\n",
       "         [-0.6846, -0.1235, -0.1279,  0.1869],\n",
       "         [-0.0426, -0.5711, -0.4615,  0.2309],\n",
       "         [ 0.0315, -0.4033, -0.4238, -0.1224],\n",
       "         [ 0.3487, -0.5676, -0.0931,  0.1178],\n",
       "         [-0.3708, -0.0878,  0.0627,  0.5553],\n",
       "         [-0.1923,  0.2953,  0.1188,  0.6443],\n",
       "         [-0.0045, -0.7875,  0.2143, -0.2263],\n",
       "         [-0.1056, -0.5017,  0.3770,  0.1916],\n",
       "         [ 0.1279,  0.4412, -0.4154, -0.5693],\n",
       "         [-0.2766,  0.5069, -0.2424, -0.3071],\n",
       "         [ 0.0649,  0.7116, -0.4932,  0.4246],\n",
       "         [-0.1462,  0.2916,  0.1241,  0.0578],\n",
       "         [-0.4214, -0.4544,  0.1207,  0.2464],\n",
       "         [-0.2116,  0.4307,  0.3868,  0.6355]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hall_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd3b646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[128000, 128000, 128006,   9125, 128007,    271,   2675,    527,    264,\n",
      "          28175,   3488,     12,    598,     86,   4776,  15592,     13,   4718,\n",
      "           3465,    374,    311,   3041,    264,  64694,   4320,    311,    279,\n",
      "           3488,   1701,    353,   3323,      9,    279,   3984,   2317,     13,\n",
      "           7557,   2771,    311,   2744,   3041,    459,   4320,     13,   5560,\n",
      "            220, 128256,     11,    220, 128257,    477,    220, 128258,  11460,\n",
      "            422,   4460,     13, 128009, 128006,    882, 128007,    271,   2014,\n",
      "            512,  15029,     50,    718,  10602,    706,   1027,  35901,   3967,\n",
      "            439,    279,    330,  52174,    315,   3765,  98681,   3343,   1102,\n",
      "            374,    832,    315,    279,   3682,  29149,   5788,  23963,    315,\n",
      "           5734,     13,  75374,     11,   2737,  20228,    323,  34153,     11,\n",
      "            374,    279,   3682,   2027,    449,   2612,    430,  21682,   1176,\n",
      "            304,   5734,    304,    220,   2550,     24,     13,  28943,  31665,\n",
      "           2997,  60290,  26390,     11,  13465,  63335,     11,  10437,  35267,\n",
      "             11,   1069,  14576,    323,  66008,     13,    328,    718,  10602,\n",
      "           1101,   1047,    279,   7928,   2612,    315,  36167,   4315,    682,\n",
      "            279,  41021,    323,    279,   2132,   7928,   2612,    315,   5554,\n",
      "          29700,    494,  83450,   2439,    304,    220,   2550,     24,     13,\n",
      "            328,    718,  10602,    374,   9257,    304,  25107,   5070,     13,\n",
      "           1102,    706,    810,   1109,    220,   9413,  13124,    315,  17033,\n",
      "          26326,  25107,   5070,   2737,   5355,  13786,     11,  71404,     11,\n",
      "            323,  57907,   1694,    279,   7928,    304,   5734,     13,    578,\n",
      "          11233,  11927,   5654,   7636,  50326,    220,   1032,     13,     18,\n",
      "              4,    315,    279,  30600,    315,  11245,     11,    220,   6365,\n",
      "              4,    315,  71404,     11,    220,   3076,      4,    315,   5355,\n",
      "          13786,     11,    323,    220,   6069,      4,    315,    279,  34928,\n",
      "           3223,    315,    279,   4459,   3224,     13,    328,    718,  10602,\n",
      "           1101,  50326,   5734,    596,   7928,  17033,   5933,   6962,  30600,\n",
      "             11,    279,   8857,    315,    902,    374,  40460,    311,    810,\n",
      "           8040,  24024,  13918,    627,  34794,  14924,     25,   3639,    527,\n",
      "            279,   3682,  29149,  16674,    315,    328,    718,  10602,     30,\n",
      "         128009, 128006,  78191, 128007]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "p1 = \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nYou are a specialized question-answering AI. Your task is to give a concise answer to the question using *only* the provided context. Make sure to always give an answer. Use <DEL_W>, <DEL_S> or <DEL_A> tokens if needed.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nContext:\\n'''\\nSichuan has been historically known as the \\\"Province of Abundance\\\". It is one of the major agricultural production bases of China. Grain, including rice and wheat, is the major product with output that ranked first in China in 1999. Commercial crops include citrus fruits, sugar cane, sweet potatoes, peaches and grapes. Sichuan also had the largest output of pork among all the provinces and the second largest output of silkworm cocoons in 1999. Sichuan is rich in mineral resources. It has more than 132 kinds of proven underground mineral resources including vanadium, titanium, and lithium being the largest in China. The Panxi region alone possesses 13.3% of the reserves of iron, 93% of titanium, 69% of vanadium, and 83% of the cobalt of the whole country. Sichuan also possesses China's largest proven natural gas reserves, the majority of which is transported to more developed eastern regions.\\n'''\\n\\nQuestion: What are the major agricultural outputs of Sichuan?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\",\n",
    "# p1 = \"What is the capital of France?\"\n",
    "inputs = tokenizer(p1, return_tensors=\"pt\")\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fa06e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# res = model.generate(input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"], output_hallucination_logits=True)\n",
    "res = model.generate(input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a5aace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128256"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.original_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721ef63a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[128000, 128000, 128006,   9125, 128007,    271,   2675,    527,    264,\n",
       "          28175,   3488,     12,    598,     86,   4776,  15592,     13,   4718,\n",
       "           3465,    374,    311,   3041,    264,  64694,   4320,    311,    279,\n",
       "           3488,   1701,    353,   3323,      9,    279,   3984,   2317,     13,\n",
       "           7557,   2771,    311,   2744,   3041,    459,   4320,     13,   5560,\n",
       "            220, 128256,     11,    220, 128257,    477,    220, 128258,  11460,\n",
       "            422,   4460,     13, 128009, 128006,    882, 128007,    271,   2014,\n",
       "            512,  15029,     50,    718,  10602,    706,   1027,  35901,   3967,\n",
       "            439,    279,    330,  52174,    315,   3765,  98681,   3343,   1102,\n",
       "            374,    832,    315,    279,   3682,  29149,   5788,  23963,    315,\n",
       "           5734,     13,  75374,     11,   2737,  20228,    323,  34153,     11,\n",
       "            374,    279,   3682,   2027,    449,   2612,    430,  21682,   1176,\n",
       "            304,   5734,    304,    220,   2550,     24,     13,  28943,  31665,\n",
       "           2997,  60290,  26390,     11,  13465,  63335,     11,  10437,  35267,\n",
       "             11,   1069,  14576,    323,  66008,     13,    328,    718,  10602,\n",
       "           1101,   1047,    279,   7928,   2612,    315,  36167,   4315,    682,\n",
       "            279,  41021,    323,    279,   2132,   7928,   2612,    315,   5554,\n",
       "          29700,    494,  83450,   2439,    304,    220,   2550,     24,     13,\n",
       "            328,    718,  10602,    374,   9257,    304,  25107,   5070,     13,\n",
       "           1102,    706,    810,   1109,    220,   9413,  13124,    315,  17033,\n",
       "          26326,  25107,   5070,   2737,   5355,  13786,     11,  71404,     11,\n",
       "            323,  57907,   1694,    279,   7928,    304,   5734,     13,    578,\n",
       "          11233,  11927,   5654,   7636,  50326,    220,   1032,     13,     18,\n",
       "              4,    315,    279,  30600,    315,  11245,     11,    220,   6365,\n",
       "              4,    315,  71404,     11,    220,   3076,      4,    315,   5355,\n",
       "          13786,     11,    323,    220,   6069,      4,    315,    279,  34928,\n",
       "           3223,    315,    279,   4459,   3224,     13,    328,    718,  10602,\n",
       "           1101,  50326,   5734,    596,   7928,  17033,   5933,   6962,  30600,\n",
       "             11,    279,   8857,    315,    902,    374,  40460,    311,    810,\n",
       "           8040,  24024,  13918,    627,  34794,  14924,     25,   3639,    527,\n",
       "            279,   3682,  29149,  16674,    315,    328,    718,  10602,     30,\n",
       "         128009, 128006,  78191, 128007,    271,     49,    560,     11,  34153,\n",
       "             11,  60290,  26390,     11,  13465,  63335,     11,  10437,  35267,\n",
       "             11,   1069,  14576,     11,  66008,     11]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a074dee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f4499d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens, hall = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba36819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|begin_of_text|><|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nYou are a specialized question-answering AI. Your task is to give a concise answer to the question using *only* the provided context. Make sure to always give an answer. Use <DEL_W>, <DEL_S> or <DEL_A> tokens if needed.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nContext:\\n\\'\\'\\'\\nSichuan has been historically known as the \"Province of Abundance\". It is one of the major agricultural production bases of China. Grain, including rice and wheat, is the major product with output that ranked first in China in 1999. Commercial crops include citrus fruits, sugar cane, sweet potatoes, peaches and grapes. Sichuan also had the largest output of pork among all the provinces and the second largest output of silkworm cocoons in 1999. Sichuan is rich in mineral resources. It has more than 132 kinds of proven underground mineral resources including vanadium, titanium, and lithium being the largest in China. The Panxi region alone possesses 13.3% of the reserves of iron, 93% of titanium, 69% of vanadium, and 83% of the cobalt of the whole country. Sichuan also possesses China\\'s largest proven natural gas reserves, the majority of which is transported to more developed eastern regions.\\n\\'\\'\\'\\n\\nQuestion: What are the major agricultural outputs of Sichuan?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nRice, wheat, citrus fruits, sugar cane, sweet potatoes, peaches, grapes,'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a88c7b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ce735f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 1: Loading and resizing original LlamaForCausalLM ---\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Load the original, standard model class\u001b[39;00m\n\u001b[1;32m     11\u001b[0m original_tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(base_model_name)\n\u001b[0;32m---> 12\u001b[0m original_model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Add tokens and resize the embeddings of the standard model\u001b[39;00m\n\u001b[1;32m     17\u001b[0m original_tokenizer\u001b[38;5;241m.\u001b[39madd_special_tokens({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madditional_special_tokens\u001b[39m\u001b[38;5;124m'\u001b[39m: special_tokens})\n",
      "File \u001b[0;32m~/miniforge3/envs/ai/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:600\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mconfig_class \u001b[38;5;241m==\u001b[39m config\u001b[38;5;241m.\u001b[39msub_configs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    599\u001b[0m         config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget_text_config()\n\u001b[0;32m--> 600\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    604\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    605\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    606\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/ai/lib/python3.11/site-packages/transformers/modeling_utils.py:316\u001b[0m, in \u001b[0;36mrestore_default_torch_dtype.<locals>._wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m old_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mget_default_dtype()\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_default_dtype(old_dtype)\n",
      "File \u001b[0;32m~/miniforge3/envs/ai/lib/python3.11/site-packages/transformers/modeling_utils.py:5061\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   5051\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5052\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   5054\u001b[0m     (\n\u001b[1;32m   5055\u001b[0m         model,\n\u001b[1;32m   5056\u001b[0m         missing_keys,\n\u001b[1;32m   5057\u001b[0m         unexpected_keys,\n\u001b[1;32m   5058\u001b[0m         mismatched_keys,\n\u001b[1;32m   5059\u001b[0m         offload_index,\n\u001b[1;32m   5060\u001b[0m         error_msgs,\n\u001b[0;32m-> 5061\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5062\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5063\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5064\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5065\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5066\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5067\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5068\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5069\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5070\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5071\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5072\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5073\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5074\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5075\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5076\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5077\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5078\u001b[0m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[1;32m   5079\u001b[0m model\u001b[38;5;241m.\u001b[39mtie_weights()\n",
      "File \u001b[0;32m~/miniforge3/envs/ai/lib/python3.11/site-packages/transformers/modeling_utils.py:5524\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, checkpoint_files, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, device_map, disk_offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_regex, device_mesh, key_mapping, weights_only)\u001b[0m\n\u001b[1;32m   5521\u001b[0m         args_list \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mtqdm(args_list, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading checkpoint shards\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5523\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m args_list:\n\u001b[0;32m-> 5524\u001b[0m         _error_msgs, disk_offload_index, cpu_offload_index \u001b[38;5;241m=\u001b[39m \u001b[43mload_shard_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5525\u001b[0m         error_msgs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m _error_msgs\n\u001b[1;32m   5527\u001b[0m \u001b[38;5;66;03m# Adjust offloaded weights name and save if needed\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/ai/lib/python3.11/site-packages/transformers/modeling_utils.py:974\u001b[0m, in \u001b[0;36mload_shard_file\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    972\u001b[0m \u001b[38;5;66;03m# Skip it with fsdp on ranks other than 0\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_fsdp_enabled() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_local_dist_rank_0() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_quantized):\n\u001b[0;32m--> 974\u001b[0m     disk_offload_index, cpu_offload_index \u001b[38;5;241m=\u001b[39m \u001b[43m_load_state_dict_into_meta_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshard_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreverse_key_renaming_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisk_offload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcpu_offload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcpu_offload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcpu_offload_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcpu_offload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_safetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_offloaded_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    987\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[43m        \u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    989\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    990\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m error_msgs, disk_offload_index, cpu_offload_index\n",
      "File \u001b[0;32m~/miniforge3/envs/ai/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/ai/lib/python3.11/site-packages/transformers/modeling_utils.py:844\u001b[0m, in \u001b[0;36m_load_state_dict_into_meta_model\u001b[0;34m(model, state_dict, shard_file, expected_keys, reverse_renaming_mapping, device_map, disk_offload_folder, disk_offload_index, cpu_offload_folder, cpu_offload_index, hf_quantizer, is_safetensors, keep_in_fp32_regex, unexpected_keys, device_mesh)\u001b[0m\n\u001b[1;32m    842\u001b[0m param \u001b[38;5;241m=\u001b[39m param[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\n\u001b[1;32m    843\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m casting_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 844\u001b[0m     param \u001b[38;5;241m=\u001b[39m \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasting_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m to_contiguous:\n\u001b[1;32m    846\u001b[0m     param \u001b[38;5;241m=\u001b[39m param\u001b[38;5;241m.\u001b[39mcontiguous()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "base_model_name = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "special_tokens = [\"<DEL_W>\", \"<DEL_S>\", \"<DEL_A>\"]\n",
    "intermediate_save_path = \"./temp_resized_model\"\n",
    "\n",
    "# --- Step 1: Load, Resize, and Save the STANDARD Llama model ---\n",
    "print(\"--- Step 1: Loading and resizing original LlamaForCausalLM ---\")\n",
    "# Load the original, standard model class\n",
    "original_tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "original_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name,\n",
    ")\n",
    "\n",
    "# Add tokens and resize the embeddings of the standard model\n",
    "original_tokenizer.add_special_tokens({'additional_special_tokens': special_tokens})\n",
    "original_model.resize_token_embeddings(len(original_tokenizer))\n",
    "\n",
    "# Save this intermediate model. It is still a LlamaForCausalLM, just with a bigger lm_head\n",
    "print(f\"--- Saving resized LlamaForCausalLM to {intermediate_save_path} ---\")\n",
    "original_model.save_pretrained(intermediate_save_path)\n",
    "original_tokenizer.save_pretrained(intermediate_save_path)\n",
    "\n",
    "# Clear memory\n",
    "del original_model\n",
    "del original_tokenizer\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2caf364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 2: Loading the RESIZED LlamaForCausalLM and testing ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128259, 2048])\n",
      "--- Output from RESIZED LlamaForCausalLM ---\n",
      "<|begin_of_text|>What is the capital of France? Paris\n",
      "The capital of France is Paris, which is also the most populous city in the country. Paris is known for its rich history, art, fashion, and cuisine. It is home to many famous landmarks, such as the Eiffel Tower\n"
     ]
    }
   ],
   "source": [
    "# --- Step 2: Load the RESIZED model and run the prompt ---\n",
    "print(\"\\n--- Step 2: Loading the RESIZED LlamaForCausalLM and testing ---\")\n",
    "# Load the model you just saved. This is still the standard class.\n",
    "resized_tokenizer = AutoTokenizer.from_pretrained(intermediate_save_path)\n",
    "resized_model = AutoModelForCausalLM.from_pretrained(\n",
    "    intermediate_save_path,\n",
    ")\n",
    "\n",
    "print(resized_model.lm_head.weight.shape)\n",
    "\n",
    "prompt = \"What is the capital of France?\"\n",
    "inputs = resized_tokenizer(prompt, return_tensors=\"pt\")\n",
    "outputs = resized_model.generate(**inputs, max_new_tokens=50)\n",
    "print(\"--- Output from RESIZED LlamaForCausalLM ---\")\n",
    "print(resized_tokenizer.decode(outputs[0], skip_special_tokens=False))\n",
    "\n",
    "# Clear memory\n",
    "del resized_model\n",
    "del resized_tokenizer\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82141c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Step 3 (Optional): Confirm your custom model behaves the same ---\n",
    "# print(\"\\n--- Step 3: Loading the RESIZED model into your custom class ---\")\n",
    "# # This is the final check. We load the same resized model, but now we\n",
    "# # let it be interpreted as your custom class.\n",
    "# # We must include the local modeling.py file via `trust_remote_code=True`.\n",
    "# custom_tokenizer = AutoTokenizer.from_pretrained(intermediate_save_path)\n",
    "# custom_model = AutoModelForCausalLM.from_pretrained(\n",
    "#     intermediate_save_path,\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "#     device_map=\"auto\",\n",
    "#     trust_remote_code=True # This will use your local `modeling.py`\n",
    "# )\n",
    "\n",
    "# inputs = custom_tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "# outputs = custom_model.generate(**inputs, max_new_tokens=50)\n",
    "# print(\"--- Output from RESIZED SelfCorrectiveLlama ---\")\n",
    "# print(custom_tokenizer.decode(outputs[0], skip_special_tokens=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76126b49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7c435e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8de426",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
