{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d76d966a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import datasets\n",
    "from functools import partial\n",
    "\n",
    "# Add the project root directory to the Python path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '../..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from src.utils.dataset_tokenization import process_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5031838c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66ea71a9bf8f4d3bb3b5af57c9c2a5cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelfCorrectiveLlama(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(128256, 2048)\n",
      "    (layers): ModuleList(\n",
      "      (0-15): 16 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
      "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
      "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
      "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
      "  (new_token_embeddings): Embedding(3, 2048)\n",
      "  (hallucination_gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
      "  (hallucination_up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
      "  (hallucination_down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
      "  (hallucination_detector): Linear(in_features=2048, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_path = \"../../self-corrective-llama_untrained\"\n",
    "# model_name = \"MathBite/self_corrective_llama_3.1_8B_untrained\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, trust_remote_code=True)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8bbcea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPECIAL_INSTRUCTION = \"\\nAs you write your answer, you can correct yourself using these tools: Use <DEL_W> to take back the word before this token, <DEL_S> to remove the entire sentence before this token, and <DEL_A> to scrap everything you've written and start again.\"\n",
    "# INSERTION_MARKER = \"<|start_header_id|>user<|end_header_id|>\"\n",
    "# DELETION_MARKERS = [\"<DEL_W>\", \"<DEL_S>\", \"<DEL_A>\"]\n",
    "# DELETION_TOKEN_IDS = tokenizer.convert_tokens_to_ids(DELETION_MARKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f473c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = \"../../dataset/train.json\"\n",
    "# dataset = datasets.load_dataset(\"json\", data_files=data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f4f05f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ef0a0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = dataset[\"train\"][7295]\n",
    "# print(sample)\n",
    "# print(sample[\"correct_response\"])\n",
    "# print(sample[\"errors\"])\n",
    "# print(sample[\"hallucinated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d595220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(7295, 7296):\n",
    "#     sample = dataset[\"train\"][i]\n",
    "    \n",
    "#     res = process_data(sample, tokenizer, SPECIAL_INSTRUCTION, INSERTION_MARKER, DELETION_TOKEN_IDS[0], DELETION_TOKEN_IDS[1], DELETION_TOKEN_IDS[2])\n",
    "\n",
    "#     hall_text_idx = [i for i, label in enumerate(res[\"hallucination_labels\"]) if label == 1]\n",
    "#     hall_text = [res[\"input_ids\"][i] for i in hall_text_idx]\n",
    "    \n",
    "#     print(sample[\"correct_response\"])\n",
    "#     print(\"================================================\")\n",
    "#     for error in sample[\"hallucinated_text\"]:\n",
    "#         print(error)\n",
    "#     print(\"================================================\")\n",
    "#     print(tokenizer.decode(hall_text))\n",
    "#     print(\"--------------------------------\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23d4948f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPECIAL_INSTRUCTION = \"\\nAs you write your answer, you can correct yourself using these tools: Use <DEL_W> to take back the word before this token, <DEL_S> to remove the entire sentence before this token, and <DEL_A> to scrap everything you've written and start again.\"\n",
    "# INSERTION_MARKER = \"<|start_header_id|>user<|end_header_id|>\"\n",
    "# DELETION_MARKERS = [\"<DEL_W>\", \"<DEL_S>\", \"<DEL_A>\"]\n",
    "# DELETION_TOKEN_IDS = tokenizer.convert_tokens_to_ids(DELETION_MARKERS)\n",
    "\n",
    "# mapper = partial(\n",
    "#     process_data,\n",
    "#     tokenizer=tokenizer,\n",
    "#     special_instruction=SPECIAL_INSTRUCTION,\n",
    "#     insertion_marker=INSERTION_MARKER,\n",
    "#     del_w_token_id=DELETION_TOKEN_IDS[0],\n",
    "#     del_s_token_id=DELETION_TOKEN_IDS[1],\n",
    "#     del_a_token_id=DELETION_TOKEN_IDS[2]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a39d7544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.cleanup_cache_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab5444da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_dataset = dataset.map(mapper, batched=False, load_from_cache_file=False)\n",
    "# tokenized_dataset = tokenized_dataset[\"train\"]\n",
    "# columns_to_remove = [\n",
    "#     \"input\", \"correct_response\", \"incorrect_response\", \n",
    "#     \"additional_info\", \"errors\", \"hallucinated_text\"\n",
    "# ]\n",
    "\n",
    "# tokenized_dataset = tokenized_dataset.remove_columns(columns_to_remove)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d3da683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ef1e043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_dataset = tokenized_dataset.train_test_split(test_size=0.1, seed=42)\n",
    "# print(split_dataset)\n",
    "# train_dataset = split_dataset['train']\n",
    "# eval_dataset = split_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1652a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_dir = \"../../dataset/training\"\n",
    "# split_dataset.save_to_disk(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a0a7360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels', 'hallucination_labels'],\n",
      "    num_rows: 36684\n",
      "})\n",
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels', 'hallucination_labels'],\n",
      "    num_rows: 4077\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.load_from_disk(\"../../dataset/training\")\n",
    "train_dataset = dataset[\"train\"]\n",
    "eval_dataset = dataset[\"test\"]\n",
    "\n",
    "print(train_dataset)\n",
    "print(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2ce570d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74dd1ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = train_dataset[5]\n",
    "# sample[\"input_ids\"] = torch.tensor(sample[\"input_ids\"]).reshape(1, -1)\n",
    "# sample[\"hallucination_labels\"] = torch.tensor(sample[\"hallucination_labels\"]).reshape(1, -1)\n",
    "# sample[\"labels\"] = torch.tensor(sample[\"labels\"]).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ac5a0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa145245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(sample[\"labels\"][sample[\"labels\"] != -100])\n",
    "# print(sample[\"hallucination_labels\"][sample[\"hallucination_labels\"] != -100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ef4db77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.forward(\n",
    "#     input_ids = sample[\"input_ids\"],\n",
    "#     hallucination_labels = sample[\"hallucination_labels\"],\n",
    "#     labels = sample[\"labels\"]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7b4236",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b1ff83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7604931c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del_tokens = [\"<DEL_W>\", \"<DEL_S>\", \"<DEL_A>\"]\n",
    "\n",
    "\n",
    "# for i in range(100, 200):\n",
    "#     sample = train_dataset[i]\n",
    "#     print(tokenizer.decode(sample[\"input_ids\"]), \"\\n\")\n",
    "\n",
    "#     for j in range(1, 4):\n",
    "#         hall_text_idx = [i for i, label in enumerate(sample[\"hallucination_labels\"]) if label == j]\n",
    "#         hall_text = [sample[\"input_ids\"][i] for i in hall_text_idx]\n",
    "\n",
    "#         print(\"--------------------------------\\n\")\n",
    "#         print(f\"Deletion token: {del_tokens[j-1]}\")\n",
    "#         print(tokenizer.decode(hall_text))\n",
    "        \n",
    "    \n",
    "#     print(\"########################################################\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e39e9fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "517ae0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import (\n",
    "#     AutoTokenizer,\n",
    "#     AutoModelForCausalLM,\n",
    "#     TrainingArguments,\n",
    "#     BitsAndBytesConfig,\n",
    "# )\n",
    "# import torch\n",
    "# from src.trainer import SelfCorrectionTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10db52ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = SelfCorrectionTrainer(model = \"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "501b545c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = train_dataset[0]\n",
    "# sample[\"input_ids\"] = torch.tensor(sample[\"input_ids\"]).reshape(1, -1)\n",
    "# sample[\"hallucination_labels\"] = torch.tensor(sample[\"hallucination_labels\"]).reshape(1, -1)\n",
    "# sample[\"labels\"] = torch.tensor(sample[\"labels\"]).reshape(1, -1)\n",
    "# print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dac8a237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = sample.copy()\n",
    "# # output[\"logits\"] = torch.tensor(output[\"input_ids\"]).reshape(1, -1, 1)\n",
    "# output[\"logits\"] = torch.zeros(1, output[\"input_ids\"].shape[-1], len(tokenizer.get_vocab())) - 100\n",
    "# for i in range(output[\"input_ids\"].shape[-1]):\n",
    "#     output[\"logits\"][0, i, output[\"input_ids\"][0, i]] = 100\n",
    "# output[\"hallucination_logits\"] = torch.tensor(output[\"hallucination_labels\"]).reshape(1, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d251c427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output[\"logits\"][0, :-1, ...] = output[\"logits\"].clone()[0, 1:, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2795b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.compute_loss(sample, output, len(tokenizer.get_vocab()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcd6ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb49a3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# logits = torch.zeros(1, 10, 100)\n",
    "# hallucination_logits = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]).reshape(1, 10, 1)\n",
    "\n",
    "# additional_logits = torch.zeros_like(logits)\n",
    "# additional_logits[:, :, -3:] = hallucination_logits\n",
    "# logits = logits + additional_logits\n",
    "# print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bbe3ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "302c8dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B-Instruct\")\n",
    "# base_model = AutoModelForCausalLM.from_pretrained(\n",
    "#     \"meta-llama/Llama-3.2-1B-Instruct\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4fd1c00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(base_model.lm_head.weight.shape)\n",
    "# print(base_model.lm_head.weight[-5:, :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "47558c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model.resize_token_embeddings(len(tokenizer.get_vocab())+3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a79e23bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(base_model.lm_head.weight.shape)\n",
    "# print(base_model.lm_head.weight[-8:, :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f4697bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "# import os\n",
    "# import sys\n",
    "# import torch\n",
    "\n",
    "# # Add the project root directory to the Python path\n",
    "# project_root = os.path.abspath(os.path.join(os.getcwd(), '../..'))\n",
    "# if project_root not in sys.path:\n",
    "#     sys.path.insert(0, project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd72f131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"../../self-corrective-llama_untrained\"\n",
    "# # path = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(path)\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "# model = AutoModelForCausalLM.from_pretrained(path, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eab96102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelfCorrectiveLlama(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0-15): 16 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
       "  (new_token_embeddings): Embedding(3, 2048)\n",
       "  (hallucination_gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "  (hallucination_up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "  (hallucination_down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "  (hallucination_detector): Linear(in_features=2048, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ef85f8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "special_token_mask:\n",
      "tensor([[False, False, False, False, False, False, False, False]])\n",
      "main_logits:\n",
      "tensor([[[ 2.8333,  3.5809,  7.0268,  ..., -1.2470, -1.2469, -1.2468],\n",
      "         [ 6.5817,  4.0679,  2.5371,  ..., -1.2149, -1.2154, -1.2152],\n",
      "         [ 2.7450,  3.9400,  2.1865,  ..., -2.5903, -2.5903, -2.5904],\n",
      "         ...,\n",
      "         [ 2.1232,  2.1697,  1.5211,  ..., -1.8789, -1.8788, -1.8786],\n",
      "         [10.2963,  6.1449,  6.6862,  ...,  0.2313,  0.2310,  0.2312],\n",
      "         [ 5.0945,  2.6669,  4.5030,  ..., -0.0846, -0.0852, -0.0852]]])\n",
      "new_logits:\n",
      "tensor([[[-0.0007, -0.0007, -0.0007],\n",
      "         [-0.0037, -0.0037, -0.0037],\n",
      "         [-0.0013, -0.0013, -0.0013],\n",
      "         [-0.0045, -0.0045, -0.0045],\n",
      "         [ 0.0033,  0.0033,  0.0033],\n",
      "         [-0.0092, -0.0092, -0.0092],\n",
      "         [ 0.0034,  0.0034,  0.0034],\n",
      "         [ 0.0042,  0.0042,  0.0042]]])\n",
      "logits:\n",
      "tensor([[[ 2.8333e+00,  3.5809e+00,  7.0268e+00,  ..., -6.5300e-04,\n",
      "          -6.5300e-04, -6.5300e-04],\n",
      "         [ 6.5817e+00,  4.0679e+00,  2.5371e+00,  ..., -3.7208e-03,\n",
      "          -3.7208e-03, -3.7208e-03],\n",
      "         [ 2.7450e+00,  3.9400e+00,  2.1865e+00,  ..., -1.3262e-03,\n",
      "          -1.3262e-03, -1.3262e-03],\n",
      "         ...,\n",
      "         [ 2.1232e+00,  2.1697e+00,  1.5211e+00,  ..., -9.2466e-03,\n",
      "          -9.2466e-03, -9.2466e-03],\n",
      "         [ 1.0296e+01,  6.1449e+00,  6.6862e+00,  ...,  3.4270e-03,\n",
      "           3.4270e-03,  3.4270e-03],\n",
      "         [ 5.0945e+00,  2.6669e+00,  4.5030e+00,  ...,  4.2194e-03,\n",
      "           4.2194e-03,  4.2194e-03]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[17.1726,  8.3706,  7.8917,  ..., -0.1116, -0.1114, -0.1114]]])\n",
      "new_logits:\n",
      "tensor([[[0.0009, 0.0009, 0.0009]]])\n",
      "logits:\n",
      "tensor([[[1.7173e+01, 8.3706e+00, 7.8917e+00,  ..., 9.4920e-04,\n",
      "          9.4920e-04, 9.4920e-04]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[ 7.3545, 12.7402, 10.7175,  ..., -0.9737, -0.9733, -0.9726]]])\n",
      "new_logits:\n",
      "tensor([[[0.0063, 0.0063, 0.0063]]])\n",
      "logits:\n",
      "tensor([[[7.3545e+00, 1.2740e+01, 1.0718e+01,  ..., 6.3303e-03,\n",
      "          6.3303e-03, 6.3303e-03]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[ 2.2578,  4.2904,  3.8237,  ..., -1.4516, -1.4516, -1.4508]]])\n",
      "new_logits:\n",
      "tensor([[[-0.0029, -0.0029, -0.0029]]])\n",
      "logits:\n",
      "tensor([[[ 2.2578e+00,  4.2904e+00,  3.8237e+00,  ..., -2.9362e-03,\n",
      "          -2.9362e-03, -2.9362e-03]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[11.3201,  8.6249,  4.5415,  ..., -0.1990, -0.1984, -0.1979]]])\n",
      "new_logits:\n",
      "tensor([[[0.0026, 0.0026, 0.0026]]])\n",
      "logits:\n",
      "tensor([[[1.1320e+01, 8.6249e+00, 4.5415e+00,  ..., 2.6412e-03,\n",
      "          2.6412e-03, 2.6412e-03]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[5.7375, 5.7065, 3.1786,  ..., 0.7692, 0.7688, 0.7690]]])\n",
      "new_logits:\n",
      "tensor([[[-0.0015, -0.0015, -0.0015]]])\n",
      "logits:\n",
      "tensor([[[ 5.7375e+00,  5.7065e+00,  3.1786e+00,  ..., -1.5185e-03,\n",
      "          -1.5185e-03, -1.5185e-03]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[15.2490,  9.7564,  6.1598,  ...,  0.2561,  0.2563,  0.2566]]])\n",
      "new_logits:\n",
      "tensor([[[-0.0049, -0.0049, -0.0049]]])\n",
      "logits:\n",
      "tensor([[[ 1.5249e+01,  9.7564e+00,  6.1598e+00,  ..., -4.8737e-03,\n",
      "          -4.8737e-03, -4.8737e-03]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[8.9504, 6.1733, 3.6315,  ..., 0.6647, 0.6643, 0.6644]]])\n",
      "new_logits:\n",
      "tensor([[[-0.0043, -0.0043, -0.0043]]])\n",
      "logits:\n",
      "tensor([[[ 8.9504e+00,  6.1733e+00,  3.6315e+00,  ..., -4.3202e-03,\n",
      "          -4.3202e-03, -4.3202e-03]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[16.7159,  8.1547,  5.8916,  ...,  2.1926,  2.1925,  2.1925]]])\n",
      "new_logits:\n",
      "tensor([[[0.0001, 0.0001, 0.0001]]])\n",
      "logits:\n",
      "tensor([[[1.6716e+01, 8.1547e+00, 5.8916e+00,  ..., 1.3613e-04,\n",
      "          1.3613e-04, 1.3613e-04]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[5.2816, 1.6201, 4.7790,  ..., 0.4941, 0.4940, 0.4942]]])\n",
      "new_logits:\n",
      "tensor([[[0.0011, 0.0011, 0.0011]]])\n",
      "logits:\n",
      "tensor([[[5.2816e+00, 1.6201e+00, 4.7790e+00,  ..., 1.0658e-03,\n",
      "          1.0658e-03, 1.0658e-03]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[12.4790,  9.9730,  5.0118,  ...,  0.2005,  0.2011,  0.2008]]])\n",
      "new_logits:\n",
      "tensor([[[-0.0031, -0.0031, -0.0031]]])\n",
      "logits:\n",
      "tensor([[[ 1.2479e+01,  9.9730e+00,  5.0118e+00,  ..., -3.0638e-03,\n",
      "          -3.0638e-03, -3.0638e-03]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[8.4621, 7.7499, 5.6197,  ..., 0.9372, 0.9371, 0.9369]]])\n",
      "new_logits:\n",
      "tensor([[[-0.0087, -0.0087, -0.0087]]])\n",
      "logits:\n",
      "tensor([[[ 8.4621,  7.7499,  5.6197,  ..., -0.0087, -0.0087, -0.0087]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[ 4.8703,  7.4341,  5.5607,  ..., -0.4222, -0.4223, -0.4224]]])\n",
      "new_logits:\n",
      "tensor([[[-0.0071, -0.0071, -0.0071]]])\n",
      "logits:\n",
      "tensor([[[ 4.8703e+00,  7.4341e+00,  5.5607e+00,  ..., -7.1203e-03,\n",
      "          -7.1203e-03, -7.1203e-03]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[5.2896, 6.4191, 3.2683,  ..., 0.0245, 0.0253, 0.0256]]])\n",
      "new_logits:\n",
      "tensor([[[-0.0056, -0.0056, -0.0056]]])\n",
      "logits:\n",
      "tensor([[[ 5.2896e+00,  6.4191e+00,  3.2683e+00,  ..., -5.6144e-03,\n",
      "          -5.6144e-03, -5.6144e-03]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[ 6.2943,  6.3330,  2.1234,  ..., -0.6089, -0.6090, -0.6088]]])\n",
      "new_logits:\n",
      "tensor([[[0.0045, 0.0045, 0.0045]]])\n",
      "logits:\n",
      "tensor([[[6.2943e+00, 6.3330e+00, 2.1234e+00,  ..., 4.4743e-03,\n",
      "          4.4743e-03, 4.4743e-03]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[10.2221,  9.0231,  4.7199,  ...,  1.0391,  1.0389,  1.0385]]])\n",
      "new_logits:\n",
      "tensor([[[-0.0032, -0.0032, -0.0032]]])\n",
      "logits:\n",
      "tensor([[[ 1.0222e+01,  9.0231e+00,  4.7199e+00,  ..., -3.2434e-03,\n",
      "          -3.2434e-03, -3.2434e-03]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[6.1850, 6.1467, 3.2146,  ..., 1.6327, 1.6321, 1.6325]]])\n",
      "new_logits:\n",
      "tensor([[[0.0007, 0.0007, 0.0007]]])\n",
      "logits:\n",
      "tensor([[[6.1850e+00, 6.1467e+00, 3.2146e+00,  ..., 6.9079e-04,\n",
      "          6.9079e-04, 6.9079e-04]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[13.7814, 10.0745,  5.2983,  ...,  2.4620,  2.4618,  2.4618]]])\n",
      "new_logits:\n",
      "tensor([[[-0.0059, -0.0059, -0.0059]]])\n",
      "logits:\n",
      "tensor([[[ 1.3781e+01,  1.0074e+01,  5.2983e+00,  ..., -5.9160e-03,\n",
      "          -5.9160e-03, -5.9160e-03]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[8.3069, 6.4306, 5.5609,  ..., 0.7939, 0.7936, 0.7935]]])\n",
      "new_logits:\n",
      "tensor([[[-0.0071, -0.0071, -0.0071]]])\n",
      "logits:\n",
      "tensor([[[ 8.3069e+00,  6.4306e+00,  5.5609e+00,  ..., -7.0568e-03,\n",
      "          -7.0568e-03, -7.0568e-03]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[7.4482, 6.8583, 5.8786,  ..., 0.7535, 0.7536, 0.7532]]])\n",
      "new_logits:\n",
      "tensor([[[-0.0094, -0.0094, -0.0094]]])\n",
      "logits:\n",
      "tensor([[[ 7.4482,  6.8583,  5.8786,  ..., -0.0094, -0.0094, -0.0094]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[9.2448, 7.7618, 4.7533,  ..., 1.9585, 1.9588, 1.9583]]])\n",
      "new_logits:\n",
      "tensor([[[-0.0056, -0.0056, -0.0056]]])\n",
      "logits:\n",
      "tensor([[[ 9.2448e+00,  7.7618e+00,  4.7533e+00,  ..., -5.5752e-03,\n",
      "          -5.5752e-03, -5.5752e-03]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[8.1607, 7.5153, 4.7840,  ..., 0.2500, 0.2501, 0.2499]]])\n",
      "new_logits:\n",
      "tensor([[[-0.0014, -0.0014, -0.0014]]])\n",
      "logits:\n",
      "tensor([[[ 8.1607e+00,  7.5153e+00,  4.7840e+00,  ..., -1.4091e-03,\n",
      "          -1.4091e-03, -1.4091e-03]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[ 3.6399,  6.4568,  2.5053,  ..., -1.9018, -1.9015, -1.9016]]])\n",
      "new_logits:\n",
      "tensor([[[-0.0010, -0.0010, -0.0010]]])\n",
      "logits:\n",
      "tensor([[[ 3.6399e+00,  6.4568e+00,  2.5053e+00,  ..., -1.0058e-03,\n",
      "          -1.0058e-03, -1.0058e-03]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[ 6.8252,  6.3925,  4.3203,  ..., -0.7371, -0.7374, -0.7377]]])\n",
      "new_logits:\n",
      "tensor([[[-0.0007, -0.0007, -0.0007]]])\n",
      "logits:\n",
      "tensor([[[ 6.8252e+00,  6.3925e+00,  4.3203e+00,  ..., -7.2300e-04,\n",
      "          -7.2300e-04, -7.2300e-04]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[11.8386,  7.6805,  5.1018,  ...,  1.9096,  1.9083,  1.9081]]])\n",
      "new_logits:\n",
      "tensor([[[-0.0057, -0.0057, -0.0057]]])\n",
      "logits:\n",
      "tensor([[[ 1.1839e+01,  7.6805e+00,  5.1018e+00,  ..., -5.7188e-03,\n",
      "          -5.7188e-03, -5.7188e-03]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[ 4.0091,  2.3421,  2.1373,  ..., -1.3788, -1.3788, -1.3793]]])\n",
      "new_logits:\n",
      "tensor([[[-9.8317e-05, -9.8317e-05, -9.8317e-05]]])\n",
      "logits:\n",
      "tensor([[[ 4.0091e+00,  2.3421e+00,  2.1373e+00,  ..., -9.8317e-05,\n",
      "          -9.8317e-05, -9.8317e-05]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[ 6.4795,  5.5884,  0.9826,  ..., -0.8522, -0.8531, -0.8532]]])\n",
      "new_logits:\n",
      "tensor([[[-0.0020, -0.0020, -0.0020]]])\n",
      "logits:\n",
      "tensor([[[ 6.4795e+00,  5.5884e+00,  9.8255e-01,  ..., -2.0278e-03,\n",
      "          -2.0278e-03, -2.0278e-03]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[ 4.9192,  2.1297,  2.1723,  ..., -0.4149, -0.4153, -0.4152]]])\n",
      "new_logits:\n",
      "tensor([[[0.0024, 0.0024, 0.0024]]])\n",
      "logits:\n",
      "tensor([[[4.9192e+00, 2.1297e+00, 2.1723e+00,  ..., 2.3689e-03,\n",
      "          2.3689e-03, 2.3689e-03]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[10.5949,  6.7376,  1.9556,  ...,  0.5296,  0.5288,  0.5287]]])\n",
      "new_logits:\n",
      "tensor([[[-0.0020, -0.0020, -0.0020]]])\n",
      "logits:\n",
      "tensor([[[ 1.0595e+01,  6.7376e+00,  1.9556e+00,  ..., -1.9778e-03,\n",
      "          -1.9778e-03, -1.9778e-03]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[ 5.4676,  2.4621,  2.5563,  ..., -0.2370, -0.2375, -0.2374]]])\n",
      "new_logits:\n",
      "tensor([[[0.0012, 0.0012, 0.0012]]])\n",
      "logits:\n",
      "tensor([[[5.4676e+00, 2.4621e+00, 2.5563e+00,  ..., 1.1551e-03,\n",
      "          1.1551e-03, 1.1551e-03]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[ 4.3075,  3.3089,  1.5435,  ..., -2.8631, -2.8630, -2.8631]]])\n",
      "new_logits:\n",
      "tensor([[[-0.0021, -0.0021, -0.0021]]])\n",
      "logits:\n",
      "tensor([[[ 4.3075e+00,  3.3089e+00,  1.5435e+00,  ..., -2.1081e-03,\n",
      "          -2.1081e-03, -2.1081e-03]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[16.0848,  7.4868,  4.4751,  ...,  1.9104,  1.9092,  1.9097]]])\n",
      "new_logits:\n",
      "tensor([[[-0.0014, -0.0014, -0.0014]]])\n",
      "logits:\n",
      "tensor([[[ 1.6085e+01,  7.4868e+00,  4.4751e+00,  ..., -1.4249e-03,\n",
      "          -1.4249e-03, -1.4249e-03]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[5.3801, 1.8570, 6.3274,  ..., 0.7755, 0.7755, 0.7757]]])\n",
      "new_logits:\n",
      "tensor([[[0.0021, 0.0021, 0.0021]]])\n",
      "logits:\n",
      "tensor([[[5.3801e+00, 1.8570e+00, 6.3274e+00,  ..., 2.1000e-03,\n",
      "          2.1000e-03, 2.1000e-03]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[ 9.8373, 10.7260,  6.4073,  ...,  0.9044,  0.9049,  0.9049]]])\n",
      "new_logits:\n",
      "tensor([[[-0.0103, -0.0103, -0.0103]]])\n",
      "logits:\n",
      "tensor([[[ 9.8373e+00,  1.0726e+01,  6.4073e+00,  ..., -1.0314e-02,\n",
      "          -1.0314e-02, -1.0314e-02]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[7.7048, 7.3002, 5.1490,  ..., 0.1917, 0.1919, 0.1917]]])\n",
      "new_logits:\n",
      "tensor([[[-0.0099, -0.0099, -0.0099]]])\n",
      "logits:\n",
      "tensor([[[ 7.7048,  7.3002,  5.1490,  ..., -0.0099, -0.0099, -0.0099]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[7.8781, 6.3981, 5.1236,  ..., 0.4025, 0.4026, 0.4025]]])\n",
      "new_logits:\n",
      "tensor([[[-0.0088, -0.0088, -0.0088]]])\n",
      "logits:\n",
      "tensor([[[ 7.8781,  6.3981,  5.1236,  ..., -0.0088, -0.0088, -0.0088]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[10.0735,  7.1790,  4.8670,  ...,  0.7805,  0.7809,  0.7803]]])\n",
      "new_logits:\n",
      "tensor([[[-0.0036, -0.0036, -0.0036]]])\n",
      "logits:\n",
      "tensor([[[ 1.0073e+01,  7.1790e+00,  4.8670e+00,  ..., -3.5659e-03,\n",
      "          -3.5659e-03, -3.5659e-03]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[ 5.4589,  5.2883, -0.0558,  ..., -1.1673, -1.1675, -1.1678]]])\n",
      "new_logits:\n",
      "tensor([[[-0.0007, -0.0007, -0.0007]]])\n",
      "logits:\n",
      "tensor([[[ 5.4589e+00,  5.2883e+00, -5.5848e-02,  ..., -7.3280e-04,\n",
      "          -7.3280e-04, -7.3280e-04]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[ 5.0302,  4.4754,  0.7811,  ..., -1.6894, -1.6886, -1.6887]]])\n",
      "new_logits:\n",
      "tensor([[[0.0034, 0.0034, 0.0034]]])\n",
      "logits:\n",
      "tensor([[[5.0302e+00, 4.4754e+00, 7.8114e-01,  ..., 3.3629e-03,\n",
      "          3.3629e-03, 3.3629e-03]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[ 3.9212,  5.0192,  0.4156,  ..., -1.9096, -1.9096, -1.9102]]])\n",
      "new_logits:\n",
      "tensor([[[-0.0005, -0.0005, -0.0005]]])\n",
      "logits:\n",
      "tensor([[[ 3.9212e+00,  5.0192e+00,  4.1562e-01,  ..., -4.8091e-04,\n",
      "          -4.8091e-04, -4.8091e-04]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[13.0608,  8.1593,  5.9894,  ...,  1.2808,  1.2800,  1.2801]]])\n",
      "new_logits:\n",
      "tensor([[[-0.0027, -0.0027, -0.0027]]])\n",
      "logits:\n",
      "tensor([[[ 1.3061e+01,  8.1593e+00,  5.9894e+00,  ..., -2.7336e-03,\n",
      "          -2.7336e-03, -2.7336e-03]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[10.4291,  8.0930,  6.2139,  ...,  1.4684,  1.4685,  1.4684]]])\n",
      "new_logits:\n",
      "tensor([[[-0.0012, -0.0012, -0.0012]]])\n",
      "logits:\n",
      "tensor([[[ 1.0429e+01,  8.0930e+00,  6.2139e+00,  ..., -1.1661e-03,\n",
      "          -1.1661e-03, -1.1661e-03]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[ 5.0286,  4.8555,  0.9443,  ..., -2.6190, -2.6189, -2.6194]]])\n",
      "new_logits:\n",
      "tensor([[[0.0063, 0.0063, 0.0063]]])\n",
      "logits:\n",
      "tensor([[[5.0286, 4.8555, 0.9443,  ..., 0.0063, 0.0063, 0.0063]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[ 1.5825,  4.4841,  2.2001,  ..., -2.8836, -2.8837, -2.8835]]])\n",
      "new_logits:\n",
      "tensor([[[0.0098, 0.0098, 0.0098]]])\n",
      "logits:\n",
      "tensor([[[1.5825, 4.4841, 2.2001,  ..., 0.0098, 0.0098, 0.0098]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[ 2.5725,  1.7513,  3.8029,  ..., -1.2688, -1.2702, -1.2701]]])\n",
      "new_logits:\n",
      "tensor([[[-0.0070, -0.0070, -0.0070]]])\n",
      "logits:\n",
      "tensor([[[ 2.5725,  1.7513,  3.8029,  ..., -0.0070, -0.0070, -0.0070]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[ 3.9160,  2.5948, -1.5181,  ..., -2.8315, -2.8318, -2.8316]]])\n",
      "new_logits:\n",
      "tensor([[[-0.0013, -0.0013, -0.0013]]])\n",
      "logits:\n",
      "tensor([[[ 3.9160e+00,  2.5948e+00, -1.5181e+00,  ..., -1.3415e-03,\n",
      "          -1.3415e-03, -1.3415e-03]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[ 4.4871,  3.0482, -0.3022,  ..., -5.3230, -5.3231, -5.3234]]])\n",
      "new_logits:\n",
      "tensor([[[-0.0011, -0.0011, -0.0011]]])\n",
      "logits:\n",
      "tensor([[[ 4.4871e+00,  3.0482e+00, -3.0219e-01,  ..., -1.0893e-03,\n",
      "          -1.0893e-03, -1.0893e-03]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[15.1902,  9.1617,  7.5277,  ...,  2.2359,  2.2356,  2.2357]]])\n",
      "new_logits:\n",
      "tensor([[[0.0014, 0.0014, 0.0014]]])\n",
      "logits:\n",
      "tensor([[[1.5190e+01, 9.1617e+00, 7.5277e+00,  ..., 1.4246e-03,\n",
      "          1.4246e-03, 1.4246e-03]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[ 1.5268,  1.8021, -0.7529,  ..., -3.2329, -3.2329, -3.2336]]])\n",
      "new_logits:\n",
      "tensor([[[0.0043, 0.0043, 0.0043]]])\n",
      "logits:\n",
      "tensor([[[ 1.5268,  1.8021, -0.7529,  ...,  0.0043,  0.0043,  0.0043]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[10.1467,  8.3112,  5.3115,  ..., -0.2205, -0.2219, -0.2212]]])\n",
      "new_logits:\n",
      "tensor([[[0.0006, 0.0006, 0.0006]]])\n",
      "logits:\n",
      "tensor([[[1.0147e+01, 8.3112e+00, 5.3115e+00,  ..., 5.5866e-04,\n",
      "          5.5866e-04, 5.5866e-04]]])\n",
      "special_token_mask:\n",
      "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False]])\n",
      "main_logits:\n",
      "tensor([[[ 2.8333,  3.5809,  7.0268,  ..., -1.2470, -1.2469, -1.2468],\n",
      "         [ 6.5817,  4.0679,  2.5371,  ..., -1.2149, -1.2154, -1.2152],\n",
      "         [ 2.7450,  3.9400,  2.1865,  ..., -2.5903, -2.5903, -2.5904],\n",
      "         ...,\n",
      "         [ 1.5268,  1.8021, -0.7529,  ..., -3.2329, -3.2329, -3.2336],\n",
      "         [10.1467,  8.3112,  5.3115,  ..., -0.2205, -0.2219, -0.2212],\n",
      "         [10.2814,  7.2115,  1.5767,  ..., -1.3611, -1.3614, -1.3618]]])\n",
      "new_logits:\n",
      "tensor([[[-6.5300e-04, -6.5300e-04, -6.5300e-04],\n",
      "         [-3.7208e-03, -3.7208e-03, -3.7208e-03],\n",
      "         [-1.3262e-03, -1.3262e-03, -1.3262e-03],\n",
      "         [-4.5429e-03, -4.5429e-03, -4.5429e-03],\n",
      "         [ 3.2869e-03,  3.2869e-03,  3.2869e-03],\n",
      "         [-9.2466e-03, -9.2466e-03, -9.2466e-03],\n",
      "         [ 3.4270e-03,  3.4270e-03,  3.4270e-03],\n",
      "         [ 4.2193e-03,  4.2193e-03,  4.2193e-03],\n",
      "         [ 9.4917e-04,  9.4917e-04,  9.4917e-04],\n",
      "         [ 6.3303e-03,  6.3303e-03,  6.3303e-03],\n",
      "         [-2.9362e-03, -2.9362e-03, -2.9362e-03],\n",
      "         [ 2.6412e-03,  2.6412e-03,  2.6412e-03],\n",
      "         [-1.5185e-03, -1.5185e-03, -1.5185e-03],\n",
      "         [-4.8736e-03, -4.8736e-03, -4.8736e-03],\n",
      "         [-4.3202e-03, -4.3202e-03, -4.3202e-03],\n",
      "         [ 1.3614e-04,  1.3614e-04,  1.3614e-04],\n",
      "         [ 1.0658e-03,  1.0658e-03,  1.0658e-03],\n",
      "         [-3.0638e-03, -3.0638e-03, -3.0638e-03],\n",
      "         [-8.6634e-03, -8.6634e-03, -8.6634e-03],\n",
      "         [-7.1203e-03, -7.1203e-03, -7.1203e-03],\n",
      "         [-5.6144e-03, -5.6144e-03, -5.6144e-03],\n",
      "         [ 4.4743e-03,  4.4743e-03,  4.4743e-03],\n",
      "         [-3.2434e-03, -3.2434e-03, -3.2434e-03],\n",
      "         [ 6.9078e-04,  6.9078e-04,  6.9078e-04],\n",
      "         [-5.9160e-03, -5.9160e-03, -5.9160e-03],\n",
      "         [-7.0568e-03, -7.0568e-03, -7.0568e-03],\n",
      "         [-9.3695e-03, -9.3695e-03, -9.3695e-03],\n",
      "         [-5.5752e-03, -5.5752e-03, -5.5752e-03],\n",
      "         [-1.4091e-03, -1.4091e-03, -1.4091e-03],\n",
      "         [-1.0058e-03, -1.0058e-03, -1.0058e-03],\n",
      "         [-7.2300e-04, -7.2300e-04, -7.2300e-04],\n",
      "         [-5.7188e-03, -5.7188e-03, -5.7188e-03],\n",
      "         [-9.8320e-05, -9.8320e-05, -9.8320e-05],\n",
      "         [-2.0277e-03, -2.0277e-03, -2.0277e-03],\n",
      "         [ 2.3689e-03,  2.3689e-03,  2.3689e-03],\n",
      "         [-1.9778e-03, -1.9778e-03, -1.9778e-03],\n",
      "         [ 1.1551e-03,  1.1551e-03,  1.1551e-03],\n",
      "         [-2.1081e-03, -2.1081e-03, -2.1081e-03],\n",
      "         [-1.4249e-03, -1.4249e-03, -1.4249e-03],\n",
      "         [ 2.1000e-03,  2.1000e-03,  2.1000e-03],\n",
      "         [-1.0314e-02, -1.0314e-02, -1.0314e-02],\n",
      "         [-9.8714e-03, -9.8714e-03, -9.8714e-03],\n",
      "         [-8.8313e-03, -8.8313e-03, -8.8313e-03],\n",
      "         [-3.5659e-03, -3.5659e-03, -3.5659e-03],\n",
      "         [-7.3279e-04, -7.3279e-04, -7.3279e-04],\n",
      "         [ 3.3629e-03,  3.3629e-03,  3.3629e-03],\n",
      "         [-4.8089e-04, -4.8089e-04, -4.8089e-04],\n",
      "         [-2.7336e-03, -2.7336e-03, -2.7336e-03],\n",
      "         [-1.1661e-03, -1.1661e-03, -1.1661e-03],\n",
      "         [ 6.2994e-03,  6.2994e-03,  6.2994e-03],\n",
      "         [ 9.7869e-03,  9.7869e-03,  9.7869e-03],\n",
      "         [-7.0429e-03, -7.0429e-03, -7.0429e-03],\n",
      "         [-1.3415e-03, -1.3415e-03, -1.3415e-03],\n",
      "         [-1.0894e-03, -1.0894e-03, -1.0894e-03],\n",
      "         [ 1.4246e-03,  1.4246e-03,  1.4246e-03],\n",
      "         [ 4.3277e-03,  4.3277e-03,  4.3277e-03],\n",
      "         [ 5.5864e-04,  5.5864e-04,  5.5864e-04],\n",
      "         [-1.2140e-03, -1.2140e-03, -1.2140e-03]]])\n",
      "logits:\n",
      "tensor([[[ 2.8333e+00,  3.5809e+00,  7.0268e+00,  ..., -6.5300e-04,\n",
      "          -6.5300e-04, -6.5300e-04],\n",
      "         [ 6.5817e+00,  4.0679e+00,  2.5371e+00,  ..., -3.7208e-03,\n",
      "          -3.7208e-03, -3.7208e-03],\n",
      "         [ 2.7450e+00,  3.9400e+00,  2.1865e+00,  ..., -1.3262e-03,\n",
      "          -1.3262e-03, -1.3262e-03],\n",
      "         ...,\n",
      "         [ 1.5268e+00,  1.8021e+00, -7.5286e-01,  ...,  4.3277e-03,\n",
      "           4.3277e-03,  4.3277e-03],\n",
      "         [ 1.0147e+01,  8.3112e+00,  5.3115e+00,  ...,  5.5864e-04,\n",
      "           5.5864e-04,  5.5864e-04],\n",
      "         [ 1.0281e+01,  7.2115e+00,  1.5767e+00,  ..., -1.2140e-03,\n",
      "          -1.2140e-03, -1.2140e-03]]])\n",
      "Generated Text: <|begin_of_text|>What is the capital of France? Paris.\n",
      "The capital of France is Paris. Paris is the most populous city in France and is known for its rich history, art, fashion, and cuisine. It is also home to many famous landmarks such as the Eiffel Tower, Notre Dame\n",
      "Hallucination Logits Shape: torch.Size([1, 50, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def generate_with_hallucination_analysis(model, tokenizer, prompt_text, max_new_tokens=50):\n",
    "    \"\"\"\n",
    "    Generates text and then runs a second pass to get hallucination logits\n",
    "    for the generated tokens, avoiding interference with the generate loop.\n",
    "    \"\"\"\n",
    "    # Ensure the model is in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # --- Pass 1: Generate the text ---\n",
    "    # We use the standard, unmodified generate method.\n",
    "    inputs = tokenizer(prompt_text, return_tensors=\"pt\").to(model.device)\n",
    "    generated_ids = model.generate(**inputs, max_new_tokens=max_new_tokens)\n",
    "    \n",
    "    # Decode the full generated text\n",
    "    generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=False)\n",
    "    \n",
    "    # --- Pass 2: Run a single forward pass on the full sequence to get all logits ---\n",
    "    # This is more efficient than collecting them step-by-step.\n",
    "    with torch.no_grad():\n",
    "        full_sequence_outputs = model(generated_ids)\n",
    "    \n",
    "    # Extract the hallucination logits from the output\n",
    "    hallucination_logits = full_sequence_outputs.hallucination_logits\n",
    "    \n",
    "    # We only care about the logits for the *newly generated* tokens.\n",
    "    # The logit at position `i` is the prediction for the token at `i+1`.\n",
    "    prompt_len = inputs.input_ids.shape[1]\n",
    "    generated_hallucination_logits = hallucination_logits[:, prompt_len-1:-1, :]\n",
    "    \n",
    "    return generated_text, generated_hallucination_logits\n",
    "\n",
    "# --- Example Usage ---\n",
    "text, hall_logits = generate_with_hallucination_analysis(\n",
    "    model, \n",
    "    tokenizer, \n",
    "    \"What is the capital of France?\",\n",
    "    max_new_tokens=50\n",
    ")\n",
    "print(\"Generated Text:\", text)\n",
    "print(\"Hallucination Logits Shape:\", hall_logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bcf4ba56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.6630e-01, -2.6610e-01,  5.5706e-01,  1.1075e-01],\n",
       "         [ 1.7694e-01, -7.5278e-01,  1.2451e-01,  1.8640e-01],\n",
       "         [-2.8399e-01, -9.9048e-01,  3.5317e-01, -4.3676e-01],\n",
       "         [ 1.4748e-01, -2.3290e-01,  1.7004e-01, -4.4632e-01],\n",
       "         [-1.7201e-03, -2.7841e-01,  9.5527e-01,  2.6030e-01],\n",
       "         [-2.8993e-01,  2.2951e-01,  4.2268e-01, -1.5192e-01],\n",
       "         [ 6.7953e-02, -4.7396e-01,  1.0069e+00, -3.4818e-02],\n",
       "         [-5.8172e-01, -1.0271e-01,  3.2743e-01, -2.8937e-01],\n",
       "         [-1.4972e-01, -6.8268e-01,  1.9739e-01,  2.0465e-01],\n",
       "         [-2.5709e-01,  2.0654e-02,  1.9311e-01, -1.4697e-01],\n",
       "         [-1.3482e-01, -7.7888e-01,  6.7434e-01, -1.9322e-01],\n",
       "         [-1.2464e-01,  2.6087e-01,  1.3779e-01,  1.5636e-01],\n",
       "         [-2.4819e-01,  3.7286e-01,  4.9692e-01, -1.9903e-01],\n",
       "         [-3.5792e-01, -2.8828e-01,  3.9076e-01,  1.6015e-01],\n",
       "         [ 2.2843e-01,  2.7824e-01, -7.4774e-02,  9.3958e-02],\n",
       "         [ 1.4222e-01, -4.8559e-01,  2.3051e-01,  3.2575e-02],\n",
       "         [-5.5558e-01,  4.3466e-01,  1.6362e-01,  2.0648e-01],\n",
       "         [-2.0711e-01, -5.8415e-01,  4.7492e-01,  4.9070e-01],\n",
       "         [-2.0899e-01, -5.0437e-02,  3.4962e-01, -2.2401e-01],\n",
       "         [-2.0484e-01,  4.7579e-01,  1.8296e-01,  2.5011e-01],\n",
       "         [ 2.4485e-01, -1.9214e-01,  5.1513e-01, -1.8958e-01],\n",
       "         [-1.0560e-01,  1.3686e-01, -1.4158e-01, -7.9544e-02],\n",
       "         [-7.4704e-01,  2.8471e-01,  9.1806e-02,  3.6103e-01],\n",
       "         [-6.4061e-01,  1.3257e-01,  4.2734e-02,  7.2070e-01],\n",
       "         [-7.5508e-02, -4.4875e-03, -1.5503e-01,  3.3939e-01],\n",
       "         [-4.2034e-01,  1.9529e-01, -2.1100e-01,  5.2165e-01],\n",
       "         [ 4.1913e-01,  4.3923e-03, -1.6492e-01,  2.2744e-01],\n",
       "         [-5.9725e-03, -1.8679e-02,  4.8111e-04,  1.2121e-01],\n",
       "         [ 1.5158e-01,  2.7815e-01,  3.3988e-02, -2.4177e-01],\n",
       "         [ 3.4347e-02, -1.4722e-02, -7.0563e-02,  6.0789e-01],\n",
       "         [-1.1720e-01,  9.3299e-02, -1.5505e-02,  2.3331e-01],\n",
       "         [-4.8435e-02, -2.5900e-01, -2.1357e-01,  3.0697e-01],\n",
       "         [-3.4831e-01,  2.2927e-01,  5.7268e-01,  2.2323e-01],\n",
       "         [-4.1749e-02, -4.1331e-01,  9.1876e-01,  8.6476e-02],\n",
       "         [-3.1213e-01,  4.6859e-01,  4.6949e-01,  1.1165e-01],\n",
       "         [-3.3670e-01,  6.5045e-01,  3.5252e-01,  1.5627e-01],\n",
       "         [-5.4554e-01, -2.4345e-01,  7.0709e-02,  1.2122e-01],\n",
       "         [-9.8581e-02, -2.8518e-01, -1.6638e-01,  5.4138e-01],\n",
       "         [-2.7331e-01,  3.7859e-01,  3.1110e-01,  5.0399e-01],\n",
       "         [-3.2518e-01,  5.5247e-01,  1.9244e-01,  2.7377e-01],\n",
       "         [-8.2911e-02,  1.6485e-01, -5.6995e-03,  1.8429e-01],\n",
       "         [-5.1664e-01, -2.3597e-02,  2.6932e-01, -2.2624e-01],\n",
       "         [-2.0779e-01, -3.6106e-01,  4.4742e-01, -1.4911e-01],\n",
       "         [ 2.0336e-01, -3.5621e-01,  1.7124e-01, -2.8208e-01],\n",
       "         [-1.4349e-01, -3.8023e-01,  4.1794e-02,  2.8030e-01],\n",
       "         [ 2.9833e-01,  2.5569e-02, -8.1493e-02,  2.6485e-02],\n",
       "         [ 2.4640e-01,  2.2768e-01,  5.9269e-01,  4.4815e-01],\n",
       "         [-3.9247e-01, -4.4153e-01,  7.0781e-01, -1.1166e-01],\n",
       "         [-1.9915e-01, -4.9479e-02,  5.9894e-01, -1.8597e-01],\n",
       "         [-6.1419e-01, -1.7580e-01,  2.3642e-01, -1.3255e-01]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hall_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5dd3b646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[128000,   3923,    374,    279,   6864,    315,   9822,     30]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "# p1 = \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nYou are a specialized question-answering AI. Your task is to give a concise answer to the question using *only* the provided context. Make sure to always give an answer. Use <DEL_W>, <DEL_S> or <DEL_A> tokens if needed.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nContext:\\n'''\\nSichuan has been historically known as the \\\"Province of Abundance\\\". It is one of the major agricultural production bases of China. Grain, including rice and wheat, is the major product with output that ranked first in China in 1999. Commercial crops include citrus fruits, sugar cane, sweet potatoes, peaches and grapes. Sichuan also had the largest output of pork among all the provinces and the second largest output of silkworm cocoons in 1999. Sichuan is rich in mineral resources. It has more than 132 kinds of proven underground mineral resources including vanadium, titanium, and lithium being the largest in China. The Panxi region alone possesses 13.3% of the reserves of iron, 93% of titanium, 69% of vanadium, and 83% of the cobalt of the whole country. Sichuan also possesses China's largest proven natural gas reserves, the majority of which is transported to more developed eastern regions.\\n'''\\n\\nQuestion: What are the major agricultural outputs of Sichuan?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\",\n",
    "p1 = \"What is the capital of France?\"\n",
    "inputs = tokenizer(p1, return_tensors=\"pt\")\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "14fa06e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "special_token_mask:\n",
      "tensor([[False, False, False, False, False, False, False, False]])\n",
      "main_logits:\n",
      "tensor([[[ 2.8333,  3.5809,  7.0268,  ..., -1.2470, -1.2469, -1.2468],\n",
      "         [ 6.5817,  4.0679,  2.5371,  ..., -1.2149, -1.2154, -1.2152],\n",
      "         [ 2.7450,  3.9400,  2.1865,  ..., -2.5903, -2.5903, -2.5904],\n",
      "         ...,\n",
      "         [ 2.1232,  2.1697,  1.5211,  ..., -1.8789, -1.8788, -1.8786],\n",
      "         [10.2963,  6.1449,  6.6862,  ...,  0.2313,  0.2310,  0.2312],\n",
      "         [ 5.0945,  2.6669,  4.5030,  ..., -0.0846, -0.0852, -0.0852]]])\n",
      "new_logits:\n",
      "tensor([[[-0.0007, -0.0007, -0.0007],\n",
      "         [-0.0037, -0.0037, -0.0037],\n",
      "         [-0.0013, -0.0013, -0.0013],\n",
      "         [-0.0045, -0.0045, -0.0045],\n",
      "         [ 0.0033,  0.0033,  0.0033],\n",
      "         [-0.0092, -0.0092, -0.0092],\n",
      "         [ 0.0034,  0.0034,  0.0034],\n",
      "         [ 0.0042,  0.0042,  0.0042]]])\n",
      "logits:\n",
      "tensor([[[ 2.8333e+00,  3.5809e+00,  7.0268e+00,  ..., -6.5300e-04,\n",
      "          -6.5300e-04, -6.5300e-04],\n",
      "         [ 6.5817e+00,  4.0679e+00,  2.5371e+00,  ..., -3.7208e-03,\n",
      "          -3.7208e-03, -3.7208e-03],\n",
      "         [ 2.7450e+00,  3.9400e+00,  2.1865e+00,  ..., -1.3262e-03,\n",
      "          -1.3262e-03, -1.3262e-03],\n",
      "         ...,\n",
      "         [ 2.1232e+00,  2.1697e+00,  1.5211e+00,  ..., -9.2466e-03,\n",
      "          -9.2466e-03, -9.2466e-03],\n",
      "         [ 1.0296e+01,  6.1449e+00,  6.6862e+00,  ...,  3.4270e-03,\n",
      "           3.4270e-03,  3.4270e-03],\n",
      "         [ 5.0945e+00,  2.6669e+00,  4.5030e+00,  ...,  4.2194e-03,\n",
      "           4.2194e-03,  4.2194e-03]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[17.1726,  8.3706,  7.8917,  ..., -0.1116, -0.1114, -0.1114]]])\n",
      "new_logits:\n",
      "tensor([[[0.0009, 0.0009, 0.0009]]])\n",
      "logits:\n",
      "tensor([[[1.7173e+01, 8.3706e+00, 7.8917e+00,  ..., 9.4920e-04,\n",
      "          9.4920e-04, 9.4920e-04]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[ 7.3545, 12.7402, 10.7175,  ..., -0.9737, -0.9733, -0.9726]]])\n",
      "new_logits:\n",
      "tensor([[[0.0063, 0.0063, 0.0063]]])\n",
      "logits:\n",
      "tensor([[[7.3545e+00, 1.2740e+01, 1.0718e+01,  ..., 6.3303e-03,\n",
      "          6.3303e-03, 6.3303e-03]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[ 2.2578,  4.2904,  3.8237,  ..., -1.4516, -1.4516, -1.4508]]])\n",
      "new_logits:\n",
      "tensor([[[-0.0029, -0.0029, -0.0029]]])\n",
      "logits:\n",
      "tensor([[[ 2.2578e+00,  4.2904e+00,  3.8237e+00,  ..., -2.9362e-03,\n",
      "          -2.9362e-03, -2.9362e-03]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[11.3201,  8.6249,  4.5415,  ..., -0.1990, -0.1984, -0.1979]]])\n",
      "new_logits:\n",
      "tensor([[[0.0026, 0.0026, 0.0026]]])\n",
      "logits:\n",
      "tensor([[[1.1320e+01, 8.6249e+00, 4.5415e+00,  ..., 2.6412e-03,\n",
      "          2.6412e-03, 2.6412e-03]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[5.7375, 5.7065, 3.1786,  ..., 0.7692, 0.7688, 0.7690]]])\n",
      "new_logits:\n",
      "tensor([[[-0.0015, -0.0015, -0.0015]]])\n",
      "logits:\n",
      "tensor([[[ 5.7375e+00,  5.7065e+00,  3.1786e+00,  ..., -1.5185e-03,\n",
      "          -1.5185e-03, -1.5185e-03]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[15.2490,  9.7564,  6.1598,  ...,  0.2561,  0.2563,  0.2566]]])\n",
      "new_logits:\n",
      "tensor([[[-0.0049, -0.0049, -0.0049]]])\n",
      "logits:\n",
      "tensor([[[ 1.5249e+01,  9.7564e+00,  6.1598e+00,  ..., -4.8737e-03,\n",
      "          -4.8737e-03, -4.8737e-03]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[8.9504, 6.1733, 3.6315,  ..., 0.6647, 0.6643, 0.6644]]])\n",
      "new_logits:\n",
      "tensor([[[-0.0043, -0.0043, -0.0043]]])\n",
      "logits:\n",
      "tensor([[[ 8.9504e+00,  6.1733e+00,  3.6315e+00,  ..., -4.3202e-03,\n",
      "          -4.3202e-03, -4.3202e-03]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[16.7159,  8.1547,  5.8916,  ...,  2.1926,  2.1925,  2.1925]]])\n",
      "new_logits:\n",
      "tensor([[[0.0001, 0.0001, 0.0001]]])\n",
      "logits:\n",
      "tensor([[[1.6716e+01, 8.1547e+00, 5.8916e+00,  ..., 1.3613e-04,\n",
      "          1.3613e-04, 1.3613e-04]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[5.2816, 1.6201, 4.7790,  ..., 0.4941, 0.4940, 0.4942]]])\n",
      "new_logits:\n",
      "tensor([[[0.0011, 0.0011, 0.0011]]])\n",
      "logits:\n",
      "tensor([[[5.2816e+00, 1.6201e+00, 4.7790e+00,  ..., 1.0658e-03,\n",
      "          1.0658e-03, 1.0658e-03]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[12.4790,  9.9730,  5.0118,  ...,  0.2005,  0.2011,  0.2008]]])\n",
      "new_logits:\n",
      "tensor([[[-0.0031, -0.0031, -0.0031]]])\n",
      "logits:\n",
      "tensor([[[ 1.2479e+01,  9.9730e+00,  5.0118e+00,  ..., -3.0638e-03,\n",
      "          -3.0638e-03, -3.0638e-03]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[8.4621, 7.7499, 5.6197,  ..., 0.9372, 0.9371, 0.9369]]])\n",
      "new_logits:\n",
      "tensor([[[-0.0087, -0.0087, -0.0087]]])\n",
      "logits:\n",
      "tensor([[[ 8.4621,  7.7499,  5.6197,  ..., -0.0087, -0.0087, -0.0087]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[ 4.8703,  7.4341,  5.5607,  ..., -0.4222, -0.4223, -0.4224]]])\n",
      "new_logits:\n",
      "tensor([[[-0.0071, -0.0071, -0.0071]]])\n",
      "logits:\n",
      "tensor([[[ 4.8703e+00,  7.4341e+00,  5.5607e+00,  ..., -7.1203e-03,\n",
      "          -7.1203e-03, -7.1203e-03]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[5.2896, 6.4191, 3.2683,  ..., 0.0245, 0.0253, 0.0256]]])\n",
      "new_logits:\n",
      "tensor([[[-0.0056, -0.0056, -0.0056]]])\n",
      "logits:\n",
      "tensor([[[ 5.2896e+00,  6.4191e+00,  3.2683e+00,  ..., -5.6144e-03,\n",
      "          -5.6144e-03, -5.6144e-03]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[ 6.2943,  6.3330,  2.1234,  ..., -0.6089, -0.6090, -0.6088]]])\n",
      "new_logits:\n",
      "tensor([[[0.0045, 0.0045, 0.0045]]])\n",
      "logits:\n",
      "tensor([[[6.2943e+00, 6.3330e+00, 2.1234e+00,  ..., 4.4743e-03,\n",
      "          4.4743e-03, 4.4743e-03]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[10.2221,  9.0231,  4.7199,  ...,  1.0391,  1.0389,  1.0385]]])\n",
      "new_logits:\n",
      "tensor([[[-0.0032, -0.0032, -0.0032]]])\n",
      "logits:\n",
      "tensor([[[ 1.0222e+01,  9.0231e+00,  4.7199e+00,  ..., -3.2434e-03,\n",
      "          -3.2434e-03, -3.2434e-03]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[6.1850, 6.1467, 3.2146,  ..., 1.6327, 1.6321, 1.6325]]])\n",
      "new_logits:\n",
      "tensor([[[0.0007, 0.0007, 0.0007]]])\n",
      "logits:\n",
      "tensor([[[6.1850e+00, 6.1467e+00, 3.2146e+00,  ..., 6.9079e-04,\n",
      "          6.9079e-04, 6.9079e-04]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[13.7814, 10.0745,  5.2983,  ...,  2.4620,  2.4618,  2.4618]]])\n",
      "new_logits:\n",
      "tensor([[[-0.0059, -0.0059, -0.0059]]])\n",
      "logits:\n",
      "tensor([[[ 1.3781e+01,  1.0074e+01,  5.2983e+00,  ..., -5.9160e-03,\n",
      "          -5.9160e-03, -5.9160e-03]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[8.3069, 6.4306, 5.5609,  ..., 0.7939, 0.7936, 0.7935]]])\n",
      "new_logits:\n",
      "tensor([[[-0.0071, -0.0071, -0.0071]]])\n",
      "logits:\n",
      "tensor([[[ 8.3069e+00,  6.4306e+00,  5.5609e+00,  ..., -7.0568e-03,\n",
      "          -7.0568e-03, -7.0568e-03]]])\n",
      "special_token_mask:\n",
      "tensor([[False]])\n",
      "main_logits:\n",
      "tensor([[[7.4482, 6.8583, 5.8786,  ..., 0.7535, 0.7536, 0.7532]]])\n",
      "new_logits:\n",
      "tensor([[[-0.0094, -0.0094, -0.0094]]])\n",
      "logits:\n",
      "tensor([[[ 7.4482,  6.8583,  5.8786,  ..., -0.0094, -0.0094, -0.0094]]])\n"
     ]
    }
   ],
   "source": [
    "# res = model.generate(input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"], output_hallucination_logits=True)\n",
    "res = model.generate(input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "17a5aace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128256"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.original_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "721ef63a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[128000,   3923,    374,    279,   6864,    315,   9822,     30,  12366,\n",
       "            627,    791,   6864,    315,   9822,    374,  12366,     13,  12366,\n",
       "            374,    279,   1455,  95551,   3363,    304,   9822,    323,    374,\n",
       "           3967]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a074dee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "91f4499d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens, hall = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6ba36819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|begin_of_text|>What is the capital of France? Paris.\\nThe capital of France is Paris. Paris is the most populous city in France and is known'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4a88c7b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ce735f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 1: Loading and resizing original LlamaForCausalLM ---\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Load the original, standard model class\u001b[39;00m\n\u001b[1;32m     11\u001b[0m original_tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(base_model_name)\n\u001b[0;32m---> 12\u001b[0m original_model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Add tokens and resize the embeddings of the standard model\u001b[39;00m\n\u001b[1;32m     17\u001b[0m original_tokenizer\u001b[38;5;241m.\u001b[39madd_special_tokens({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madditional_special_tokens\u001b[39m\u001b[38;5;124m'\u001b[39m: special_tokens})\n",
      "File \u001b[0;32m~/miniforge3/envs/ai/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:600\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mconfig_class \u001b[38;5;241m==\u001b[39m config\u001b[38;5;241m.\u001b[39msub_configs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    599\u001b[0m         config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget_text_config()\n\u001b[0;32m--> 600\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    604\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    605\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    606\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/ai/lib/python3.11/site-packages/transformers/modeling_utils.py:316\u001b[0m, in \u001b[0;36mrestore_default_torch_dtype.<locals>._wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m old_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mget_default_dtype()\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_default_dtype(old_dtype)\n",
      "File \u001b[0;32m~/miniforge3/envs/ai/lib/python3.11/site-packages/transformers/modeling_utils.py:5061\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   5051\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5052\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   5054\u001b[0m     (\n\u001b[1;32m   5055\u001b[0m         model,\n\u001b[1;32m   5056\u001b[0m         missing_keys,\n\u001b[1;32m   5057\u001b[0m         unexpected_keys,\n\u001b[1;32m   5058\u001b[0m         mismatched_keys,\n\u001b[1;32m   5059\u001b[0m         offload_index,\n\u001b[1;32m   5060\u001b[0m         error_msgs,\n\u001b[0;32m-> 5061\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5062\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5063\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5064\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5065\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5066\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5067\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5068\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5069\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5070\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5071\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5072\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5073\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5074\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5075\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5076\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5077\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5078\u001b[0m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[1;32m   5079\u001b[0m model\u001b[38;5;241m.\u001b[39mtie_weights()\n",
      "File \u001b[0;32m~/miniforge3/envs/ai/lib/python3.11/site-packages/transformers/modeling_utils.py:5524\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, checkpoint_files, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, device_map, disk_offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_regex, device_mesh, key_mapping, weights_only)\u001b[0m\n\u001b[1;32m   5521\u001b[0m         args_list \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mtqdm(args_list, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading checkpoint shards\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5523\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m args_list:\n\u001b[0;32m-> 5524\u001b[0m         _error_msgs, disk_offload_index, cpu_offload_index \u001b[38;5;241m=\u001b[39m \u001b[43mload_shard_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5525\u001b[0m         error_msgs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m _error_msgs\n\u001b[1;32m   5527\u001b[0m \u001b[38;5;66;03m# Adjust offloaded weights name and save if needed\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/ai/lib/python3.11/site-packages/transformers/modeling_utils.py:974\u001b[0m, in \u001b[0;36mload_shard_file\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    972\u001b[0m \u001b[38;5;66;03m# Skip it with fsdp on ranks other than 0\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_fsdp_enabled() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_local_dist_rank_0() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_quantized):\n\u001b[0;32m--> 974\u001b[0m     disk_offload_index, cpu_offload_index \u001b[38;5;241m=\u001b[39m \u001b[43m_load_state_dict_into_meta_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshard_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreverse_key_renaming_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisk_offload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcpu_offload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcpu_offload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcpu_offload_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcpu_offload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_safetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_offloaded_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    987\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[43m        \u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    989\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    990\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m error_msgs, disk_offload_index, cpu_offload_index\n",
      "File \u001b[0;32m~/miniforge3/envs/ai/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/ai/lib/python3.11/site-packages/transformers/modeling_utils.py:844\u001b[0m, in \u001b[0;36m_load_state_dict_into_meta_model\u001b[0;34m(model, state_dict, shard_file, expected_keys, reverse_renaming_mapping, device_map, disk_offload_folder, disk_offload_index, cpu_offload_folder, cpu_offload_index, hf_quantizer, is_safetensors, keep_in_fp32_regex, unexpected_keys, device_mesh)\u001b[0m\n\u001b[1;32m    842\u001b[0m param \u001b[38;5;241m=\u001b[39m param[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\n\u001b[1;32m    843\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m casting_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 844\u001b[0m     param \u001b[38;5;241m=\u001b[39m \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasting_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m to_contiguous:\n\u001b[1;32m    846\u001b[0m     param \u001b[38;5;241m=\u001b[39m param\u001b[38;5;241m.\u001b[39mcontiguous()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "base_model_name = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "special_tokens = [\"<DEL_W>\", \"<DEL_S>\", \"<DEL_A>\"]\n",
    "intermediate_save_path = \"./temp_resized_model\"\n",
    "\n",
    "# --- Step 1: Load, Resize, and Save the STANDARD Llama model ---\n",
    "print(\"--- Step 1: Loading and resizing original LlamaForCausalLM ---\")\n",
    "# Load the original, standard model class\n",
    "original_tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "original_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name,\n",
    ")\n",
    "\n",
    "# Add tokens and resize the embeddings of the standard model\n",
    "original_tokenizer.add_special_tokens({'additional_special_tokens': special_tokens})\n",
    "original_model.resize_token_embeddings(len(original_tokenizer))\n",
    "\n",
    "# Save this intermediate model. It is still a LlamaForCausalLM, just with a bigger lm_head\n",
    "print(f\"--- Saving resized LlamaForCausalLM to {intermediate_save_path} ---\")\n",
    "original_model.save_pretrained(intermediate_save_path)\n",
    "original_tokenizer.save_pretrained(intermediate_save_path)\n",
    "\n",
    "# Clear memory\n",
    "del original_model\n",
    "del original_tokenizer\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2caf364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 2: Loading the RESIZED LlamaForCausalLM and testing ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128259, 2048])\n",
      "--- Output from RESIZED LlamaForCausalLM ---\n",
      "<|begin_of_text|>What is the capital of France? Paris\n",
      "The capital of France is Paris, which is also the most populous city in the country. Paris is known for its rich history, art, fashion, and cuisine. It is home to many famous landmarks, such as the Eiffel Tower\n"
     ]
    }
   ],
   "source": [
    "# --- Step 2: Load the RESIZED model and run the prompt ---\n",
    "print(\"\\n--- Step 2: Loading the RESIZED LlamaForCausalLM and testing ---\")\n",
    "# Load the model you just saved. This is still the standard class.\n",
    "resized_tokenizer = AutoTokenizer.from_pretrained(intermediate_save_path)\n",
    "resized_model = AutoModelForCausalLM.from_pretrained(\n",
    "    intermediate_save_path,\n",
    ")\n",
    "\n",
    "print(resized_model.lm_head.weight.shape)\n",
    "\n",
    "prompt = \"What is the capital of France?\"\n",
    "inputs = resized_tokenizer(prompt, return_tensors=\"pt\")\n",
    "outputs = resized_model.generate(**inputs, max_new_tokens=50)\n",
    "print(\"--- Output from RESIZED LlamaForCausalLM ---\")\n",
    "print(resized_tokenizer.decode(outputs[0], skip_special_tokens=False))\n",
    "\n",
    "# Clear memory\n",
    "del resized_model\n",
    "del resized_tokenizer\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82141c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Step 3 (Optional): Confirm your custom model behaves the same ---\n",
    "# print(\"\\n--- Step 3: Loading the RESIZED model into your custom class ---\")\n",
    "# # This is the final check. We load the same resized model, but now we\n",
    "# # let it be interpreted as your custom class.\n",
    "# # We must include the local modeling.py file via `trust_remote_code=True`.\n",
    "# custom_tokenizer = AutoTokenizer.from_pretrained(intermediate_save_path)\n",
    "# custom_model = AutoModelForCausalLM.from_pretrained(\n",
    "#     intermediate_save_path,\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "#     device_map=\"auto\",\n",
    "#     trust_remote_code=True # This will use your local `modeling.py`\n",
    "# )\n",
    "\n",
    "# inputs = custom_tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "# outputs = custom_model.generate(**inputs, max_new_tokens=50)\n",
    "# print(\"--- Output from RESIZED SelfCorrectiveLlama ---\")\n",
    "# print(custom_tokenizer.decode(outputs[0], skip_special_tokens=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76126b49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7c435e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8de426",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
