{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbc07bab-8517-4cfc-beb1-807f1a2092f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T17:36:46.216034Z",
     "iopub.status.busy": "2025-08-12T17:36:46.215737Z",
     "iopub.status.idle": "2025-08-12T17:36:48.766126Z",
     "shell.execute_reply": "2025-08-12T17:36:48.765378Z",
     "shell.execute_reply.started": "2025-08-12T17:36:46.216005Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.12/site-packages (4.53.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /opt/conda/lib/python3.12/site-packages (from transformers) (0.33.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.12/site-packages (from transformers) (0.21.4.dev0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.12.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (2025.6.15)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72803618-120f-41b2-b4b6-6b4ad0217d75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T17:36:48.767880Z",
     "iopub.status.busy": "2025-08-12T17:36:48.767647Z",
     "iopub.status.idle": "2025-08-12T17:36:50.444259Z",
     "shell.execute_reply": "2025-08-12T17:36:50.443414Z",
     "shell.execute_reply.started": "2025-08-12T17:36:48.767856Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.12/site-packages (2.2.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.12/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /opt/conda/lib/python3.12/site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.12/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.12/site-packages (from datasets) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.12/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.12/site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.12/site-packages (from fsspec[http]>=2021.05.0->datasets) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.12/site-packages (from datasets) (3.12.13)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.12/site-packages (from datasets) (0.33.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.12/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.18.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (1.1.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.14.1)\n",
      "Requirement already satisfied: urllib3>=1.25.10 in /opt/conda/lib/python3.12/site-packages (from responses<0.19->datasets) (1.26.19)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests>=2.19.0->datasets) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests>=2.19.0->datasets) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests>=2.19.0->datasets) (2025.6.15)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets) (1.20.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "156f9590-48fa-4276-a087-775634155a11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T17:36:50.445711Z",
     "iopub.status.busy": "2025-08-12T17:36:50.445476Z",
     "iopub.status.idle": "2025-08-12T17:36:53.780098Z",
     "shell.execute_reply": "2025-08-12T17:36:53.779322Z",
     "shell.execute_reply.started": "2025-08-12T17:36:50.445687Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sagemaker in /opt/conda/lib/python3.12/site-packages (2.245.0)\n",
      "Collecting sagemaker\n",
      "  Using cached sagemaker-2.250.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting attrs<26,>=24 (from sagemaker)\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: boto3<2.0,>=1.35.36 in /opt/conda/lib/python3.12/site-packages (from sagemaker) (1.37.1)\n",
      "Requirement already satisfied: cloudpickle>=2.2.1 in /opt/conda/lib/python3.12/site-packages (from sagemaker) (3.1.1)\n",
      "Requirement already satisfied: docker in /opt/conda/lib/python3.12/site-packages (from sagemaker) (7.1.0)\n",
      "Requirement already satisfied: fastapi in /opt/conda/lib/python3.12/site-packages (from sagemaker) (0.115.14)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.12/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: graphene<4,>=3 in /opt/conda/lib/python3.12/site-packages (from sagemaker) (3.4.3)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /opt/conda/lib/python3.12/site-packages (from sagemaker) (6.10.0)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.12/site-packages (from sagemaker) (4.23.0)\n",
      "Requirement already satisfied: numpy==1.26.4 in /opt/conda/lib/python3.12/site-packages (from sagemaker) (1.26.4)\n",
      "Requirement already satisfied: omegaconf<3,>=2.2 in /opt/conda/lib/python3.12/site-packages (from sagemaker) (2.3.0)\n",
      "Requirement already satisfied: packaging<25,>=23.0 in /opt/conda/lib/python3.12/site-packages (from sagemaker) (24.2)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (from sagemaker) (2.2.3)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.12/site-packages (from sagemaker) (0.3.4)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.12/site-packages (from sagemaker) (4.3.8)\n",
      "Requirement already satisfied: protobuf<6.32,>=3.12 in /opt/conda/lib/python3.12/site-packages (from sagemaker) (5.28.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.12/site-packages (from sagemaker) (5.9.8)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in /opt/conda/lib/python3.12/site-packages (from sagemaker) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (from sagemaker) (2.32.4)\n",
      "Requirement already satisfied: sagemaker-core<2.0.0,>=1.0.17 in /opt/conda/lib/python3.12/site-packages (from sagemaker) (1.0.32)\n",
      "Requirement already satisfied: schema in /opt/conda/lib/python3.12/site-packages (from sagemaker) (0.7.7)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.12/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: tblib<4,>=1.7.0 in /opt/conda/lib/python3.12/site-packages (from sagemaker) (3.1.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.12/site-packages (from sagemaker) (4.67.1)\n",
      "Requirement already satisfied: urllib3<3.0.0,>=1.26.8 in /opt/conda/lib/python3.12/site-packages (from sagemaker) (1.26.19)\n",
      "Requirement already satisfied: uvicorn in /opt/conda/lib/python3.12/site-packages (from sagemaker) (0.35.0)\n",
      "Requirement already satisfied: botocore<1.38.0,>=1.37.1 in /opt/conda/lib/python3.12/site-packages (from boto3<2.0,>=1.35.36->sagemaker) (1.37.1)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.12/site-packages (from boto3<2.0,>=1.35.36->sagemaker) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /opt/conda/lib/python3.12/site-packages (from boto3<2.0,>=1.35.36->sagemaker) (0.11.3)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.12/site-packages (from botocore<1.38.0,>=1.37.1->boto3<2.0,>=1.35.36->sagemaker) (2.9.0.post0)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in /opt/conda/lib/python3.12/site-packages (from graphene<4,>=3->sagemaker) (3.2.6)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /opt/conda/lib/python3.12/site-packages (from graphene<4,>=3->sagemaker) (3.2.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7.1 in /opt/conda/lib/python3.12/site-packages (from graphene<4,>=3->sagemaker) (4.14.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.12/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker) (3.23.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /opt/conda/lib/python3.12/site-packages (from omegaconf<3,>=2.2->sagemaker) (4.9.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.38.0,>=1.37.1->boto3<2.0,>=1.35.36->sagemaker) (1.17.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /opt/conda/lib/python3.12/site-packages (from sagemaker-core<2.0.0,>=1.0.17->sagemaker) (2.11.7)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.0.0 in /opt/conda/lib/python3.12/site-packages (from sagemaker-core<2.0.0,>=1.0.17->sagemaker) (13.9.4)\n",
      "Requirement already satisfied: mock<5.0,>4.0 in /opt/conda/lib/python3.12/site-packages (from sagemaker-core<2.0.0,>=1.0.17->sagemaker) (4.0.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.12/site-packages (from jsonschema->sagemaker) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.12/site-packages (from jsonschema->sagemaker) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.12/site-packages (from jsonschema->sagemaker) (0.26.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/conda/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/conda/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (0.4.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.12/site-packages (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.12/site-packages (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (0.1.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests->sagemaker) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests->sagemaker) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests->sagemaker) (2025.6.15)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /opt/conda/lib/python3.12/site-packages (from fastapi->sagemaker) (0.46.2)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /opt/conda/lib/python3.12/site-packages (from starlette<0.47.0,>=0.40.0->fastapi->sagemaker) (4.9.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.12/site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi->sagemaker) (1.3.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas->sagemaker) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas->sagemaker) (2025.2)\n",
      "Requirement already satisfied: ppft>=1.7.7 in /opt/conda/lib/python3.12/site-packages (from pathos->sagemaker) (1.7.7)\n",
      "Requirement already satisfied: dill>=0.4.0 in /opt/conda/lib/python3.12/site-packages (from pathos->sagemaker) (0.4.0)\n",
      "Requirement already satisfied: pox>=0.3.6 in /opt/conda/lib/python3.12/site-packages (from pathos->sagemaker) (0.3.6)\n",
      "Requirement already satisfied: multiprocess>=0.70.18 in /opt/conda/lib/python3.12/site-packages (from pathos->sagemaker) (0.70.18)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.12/site-packages (from uvicorn->sagemaker) (8.2.1)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.12/site-packages (from uvicorn->sagemaker) (0.16.0)\n",
      "Using cached sagemaker-2.250.0-py3-none-any.whl (1.7 MB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Installing collected packages: attrs, sagemaker\n",
      "\u001b[2K  Attempting uninstall: attrs\n",
      "\u001b[2K    Found existing installation: attrs 23.2.0\n",
      "\u001b[2K    Uninstalling attrs-23.2.0:\n",
      "\u001b[2K      Successfully uninstalled attrs-23.2.0\n",
      "\u001b[2K  Attempting uninstall: sagemaker\n",
      "\u001b[2K    Found existing installation: sagemaker 2.245.0\n",
      "\u001b[2K    Uninstalling sagemaker-2.245.0:0m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/2\u001b[0m [sagemaker]\n",
      "\u001b[2K      Successfully uninstalled sagemaker-2.245.0━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/2\u001b[0m [sagemaker]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [sagemaker]/2\u001b[0m [sagemaker]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sagemaker-studio-analytics-extension 0.2.0 requires sparkmagic==0.22.0, but you have sparkmagic 0.21.0 which is incompatible.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed attrs-25.3.0 sagemaker-2.250.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce8a8b55-aa59-4af1-a9ce-1341f1d9c900",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T17:36:53.781507Z",
     "iopub.status.busy": "2025-08-12T17:36:53.781269Z",
     "iopub.status.idle": "2025-08-12T17:36:55.414853Z",
     "shell.execute_reply": "2025-08-12T17:36:55.414094Z",
     "shell.execute_reply.started": "2025-08-12T17:36:53.781483Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: s3fs in /opt/conda/lib/python3.12/site-packages (2024.12.0)\n",
      "Requirement already satisfied: aiobotocore<3.0.0,>=2.5.4 in /opt/conda/lib/python3.12/site-packages (from s3fs) (2.21.1)\n",
      "Requirement already satisfied: fsspec==2024.12.0.* in /opt/conda/lib/python3.12/site-packages (from s3fs) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.12/site-packages (from s3fs) (3.12.13)\n",
      "Requirement already satisfied: aioitertools<1.0.0,>=0.5.1 in /opt/conda/lib/python3.12/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (0.12.0)\n",
      "Requirement already satisfied: botocore<1.37.2,>=1.37.0 in /opt/conda/lib/python3.12/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (1.37.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.12/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (2.9.0.post0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.12/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (1.0.1)\n",
      "Requirement already satisfied: multidict<7.0.0,>=6.0.0 in /opt/conda/lib/python3.12/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (6.6.3)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.10.10 in /opt/conda/lib/python3.12/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (1.17.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.6.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.20.1)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/conda/lib/python3.12/site-packages (from botocore<1.37.2,>=1.37.0->aiobotocore<3.0.0,>=2.5.4->s3fs) (1.26.19)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil<3.0.0,>=2.1->aiobotocore<3.0.0,>=2.5.4->s3fs) (1.17.0)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in /opt/conda/lib/python3.12/site-packages (from aiosignal>=1.1.2->aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (4.14.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaa2e217-7c43-4b8e-a084-ab1a878982e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T17:36:55.416220Z",
     "iopub.status.busy": "2025-08-12T17:36:55.415915Z",
     "iopub.status.idle": "2025-08-12T17:36:57.156168Z",
     "shell.execute_reply": "2025-08-12T17:36:57.155346Z",
     "shell.execute_reply.started": "2025-08-12T17:36:55.416193Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting loguru\n",
      "  Using cached loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
      "Using cached loguru-0.7.3-py3-none-any.whl (61 kB)\n",
      "Installing collected packages: loguru\n",
      "Successfully installed loguru-0.7.3\n"
     ]
    }
   ],
   "source": [
    "!pip install loguru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fbff4c7-6220-4a64-9ee3-d4b89b270741",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T17:36:57.157531Z",
     "iopub.status.busy": "2025-08-12T17:36:57.157148Z",
     "iopub.status.idle": "2025-08-12T17:36:59.792420Z",
     "shell.execute_reply": "2025-08-12T17:36:59.791781Z",
     "shell.execute_reply.started": "2025-08-12T17:36:57.157507Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker.huggingface import HuggingFace\n",
    "import boto3\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# --- Configuration ---\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13492ee7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T17:36:59.793455Z",
     "iopub.status.busy": "2025-08-12T17:36:59.793244Z",
     "iopub.status.idle": "2025-08-12T17:36:59.798657Z",
     "shell.execute_reply": "2025-08-12T17:36:59.796103Z",
     "shell.execute_reply.started": "2025-08-12T17:36:59.793436Z"
    }
   },
   "outputs": [],
   "source": [
    "# IAM role for SageMaker\n",
    "# iam_role = \"arn:aws:iam::551529993308:role/service-role/AmazonSageMaker-ExecutionRole-20250711T075198\"\n",
    "iam_role = os.getenv(\"SAGEMAKER_IAM_ROLE\")\n",
    "# # S3 bucket for data and model artifacts\n",
    "# s3_bucket = \"self-corrective-llm-data\" \n",
    "s3_bucket = os.getenv(\"S3_BUCKET\")\n",
    "\n",
    "# try:\n",
    "# \trole = sagemaker.get_execution_role()\n",
    "#     # role = \"arn:aws:iam::551529993308:role/service-role/AmazonSageMaker-ExecutionRole-20250711T075198\"\n",
    "# except ValueError:\n",
    "# \tiam = boto3.client('iam')\n",
    "# \trole = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdb8d9ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T17:36:59.799830Z",
     "iopub.status.busy": "2025-08-12T17:36:59.799625Z",
     "iopub.status.idle": "2025-08-12T17:36:59.803989Z",
     "shell.execute_reply": "2025-08-12T17:36:59.803400Z",
     "shell.execute_reply.started": "2025-08-12T17:36:59.799812Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define S3 paths\n",
    "base_s3_uri = f\"s3://{s3_bucket}\"\n",
    "base_model_s3_uri = f\"{base_s3_uri}/self-corrective-llm-not-trained\"\n",
    "dataset_s3_uri = f\"{base_s3_uri}/dataset/training_data\"\n",
    "output_s3_uri = f\"{base_s3_uri}/trained_model/output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7fc57a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T17:36:59.805278Z",
     "iopub.status.busy": "2025-08-12T17:36:59.805002Z",
     "iopub.status.idle": "2025-08-12T17:37:00.123207Z",
     "shell.execute_reply": "2025-08-12T17:37:00.122408Z",
     "shell.execute_reply.started": "2025-08-12T17:36:59.805257Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Hyperparameters ---\n",
    "hyperparameters = {\n",
    "    # Core parameters\n",
    "    \"epochs\": 1,\n",
    "    \"learning_rate\": 2e-4,\n",
    "    \"alpha\": 0.7,\n",
    "    \"pos_weight\": 10.0,\n",
    "\n",
    "    # Batching and memory\n",
    "    \"train_batch_size\": 2,\n",
    "    \"eval_batch_size\": 2,\n",
    "    \"gradient_accumulation_steps\": 8,\n",
    "\n",
    "    # LoRA parameters\n",
    "    \"lora_r\": 16,\n",
    "    \"lora_alpha\": 32,\n",
    "    \"lora_dropout\": 0.05,\n",
    "\n",
    "    # Optimizer and scheduler\n",
    "    \"optim\": \"paged_adamw_8bit\",\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"lr_scheduler_type\": \"cosine\",\n",
    "\n",
    "    # Logging and saving\n",
    "    \"logging_steps\": 10,\n",
    "    \"eval_steps\": 50,\n",
    "    \"save_steps\": 50,\n",
    "}\n",
    "\n",
    "wandb_api_key = os.getenv(\"WANDB_API_KEY\")\n",
    "environment = {\n",
    "    \"WANDB_API_KEY\": wandb_api_key,\n",
    "}\n",
    "\n",
    "# --- SageMaker Estimator ---\n",
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point=\"train.py\",          # Your training script\n",
    "    source_dir=\"../../scripts\",         # Directory containing the script\n",
    "    instance_type=\"ml.g5.4xlarge\",   # Instance type for training\n",
    "    volume_size=100,\n",
    "    instance_count=1,\n",
    "    role=iam_role,\n",
    "    transformers_version=\"4.49\",     # Version of transformers\n",
    "    pytorch_version=\"2.5\",           # Version of PyTorch\n",
    "    py_version=\"py311\",              # Python version\n",
    "    hyperparameters=hyperparameters,\n",
    "    output_path=output_s3_uri,\n",
    "    environment=environment,\n",
    "    # Dependencies from your project\n",
    "    dependencies=[\"../../src\"],\n",
    "    # Input channels for data and base model\n",
    "    sagemaker_session=sagemaker.Session(),\n",
    "    # input_mode='File',\n",
    "#     distribution={\"torch_distributed\": {\"enabled\": True}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6531de7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T17:37:00.124553Z",
     "iopub.status.busy": "2025-08-12T17:37:00.124111Z",
     "iopub.status.idle": "2025-08-12T17:46:08.306851Z",
     "shell.execute_reply": "2025-08-12T17:46:08.306066Z",
     "shell.execute_reply.started": "2025-08-12T17:37:00.124521Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: huggingface-pytorch-training-2025-08-12-17-37-00-151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-12 17:37:05 Starting - Starting the training job\n",
      "2025-08-12 17:37:05 Pending - Training job waiting for capacity......\n",
      "2025-08-12 17:37:48 Pending - Preparing the instances for training...\n",
      "2025-08-12 17:38:17 Downloading - Downloading input data.........\n",
      "2025-08-12 17:39:57 Downloading - Downloading the training image............\n",
      "2025-08-12 17:41:49 Training - Training image download completed. Training in progress....\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34mCUDA compat package should be installed for NVIDIA driver smaller than 550.163.01\u001b[0m\n",
      "\u001b[34mCurrent installed NVIDIA driver version is 570.172.08\u001b[0m\n",
      "\u001b[34mSkipping CUDA compat setup as newer NVIDIA driver is installed\u001b[0m\n",
      "\u001b[34m2025-08-12 17:42:26,273 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2025-08-12 17:42:26,291 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-08-12 17:42:26,300 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2025-08-12 17:42:26,301 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2025-08-12 17:42:27,725 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting datasets==4.0.0 (from -r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\u001b[0m\n",
      "\u001b[34mCollecting wandb (from -r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading wandb-0.21.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets==4.0.0->-r requirements.txt (line 1)) (3.18.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from datasets==4.0.0->-r requirements.txt (line 1)) (1.26.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets==4.0.0->-r requirements.txt (line 1)) (21.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets==4.0.0->-r requirements.txt (line 1)) (0.3.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets==4.0.0->-r requirements.txt (line 1)) (2.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.11/site-packages (from datasets==4.0.0->-r requirements.txt (line 1)) (2.32.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.11/site-packages (from datasets==4.0.0->-r requirements.txt (line 1)) (4.66.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets==4.0.0->-r requirements.txt (line 1)) (3.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.11/site-packages (from datasets==4.0.0->-r requirements.txt (line 1)) (0.70.16)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0->-r requirements.txt (line 1)) (2024.12.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: huggingface-hub>=0.24.0 in /opt/conda/lib/python3.11/site-packages (from datasets==4.0.0->-r requirements.txt (line 1)) (0.29.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from datasets==4.0.0->-r requirements.txt (line 1)) (24.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from datasets==4.0.0->-r requirements.txt (line 1)) (6.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0->-r requirements.txt (line 1)) (3.12.14)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.11/site-packages (from wandb->-r requirements.txt (line 2)) (8.2.1)\u001b[0m\n",
      "\u001b[34mCollecting gitpython!=3.1.29,>=1.0.0 (from wandb->-r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: platformdirs in /opt/conda/lib/python3.11/site-packages (from wandb->-r requirements.txt (line 2)) (4.3.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /opt/conda/lib/python3.11/site-packages (from wandb->-r requirements.txt (line 2)) (6.31.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pydantic<3 in /opt/conda/lib/python3.11/site-packages (from wandb->-r requirements.txt (line 2)) (2.11.7)\u001b[0m\n",
      "\u001b[34mCollecting sentry-sdk>=2.0.0 (from wandb->-r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading sentry_sdk-2.34.1-py2.py3-none-any.whl.metadata (10 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions<5,>=4.8 in /opt/conda/lib/python3.11/site-packages (from wandb->-r requirements.txt (line 2)) (4.14.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from pydantic<3->wandb->-r requirements.txt (line 2)) (0.7.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pydantic-core==2.33.2 in /opt/conda/lib/python3.11/site-packages (from pydantic<3->wandb->-r requirements.txt (line 2)) (2.33.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-inspection>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from pydantic<3->wandb->-r requirements.txt (line 2)) (0.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets==4.0.0->-r requirements.txt (line 1)) (3.4.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets==4.0.0->-r requirements.txt (line 1)) (3.10)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets==4.0.0->-r requirements.txt (line 1)) (2.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets==4.0.0->-r requirements.txt (line 1)) (2025.7.14)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0->-r requirements.txt (line 1)) (2.6.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiosignal>=1.4.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0->-r requirements.txt (line 1)) (1.4.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0->-r requirements.txt (line 1)) (25.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0->-r requirements.txt (line 1)) (1.7.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0->-r requirements.txt (line 1)) (6.6.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0->-r requirements.txt (line 1)) (0.3.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0->-r requirements.txt (line 1)) (1.20.1)\u001b[0m\n",
      "\u001b[34mCollecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets==4.0.0->-r requirements.txt (line 1)) (2.9.0.post0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets==4.0.0->-r requirements.txt (line 1)) (2025.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets==4.0.0->-r requirements.txt (line 1)) (2025.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets==4.0.0->-r requirements.txt (line 1)) (1.17.0)\u001b[0m\n",
      "\u001b[34mDownloading datasets-4.0.0-py3-none-any.whl (494 kB)\u001b[0m\n",
      "\u001b[34mDownloading wandb-0.21.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.4 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 22.4/22.4 MB 184.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading gitpython-3.1.45-py3-none-any.whl (208 kB)\u001b[0m\n",
      "\u001b[34mDownloading gitdb-4.0.12-py3-none-any.whl (62 kB)\u001b[0m\n",
      "\u001b[34mDownloading smmap-5.0.2-py3-none-any.whl (24 kB)\u001b[0m\n",
      "\u001b[34mDownloading sentry_sdk-2.34.1-py2.py3-none-any.whl (357 kB)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: smmap, sentry-sdk, gitdb, gitpython, wandb, datasets\u001b[0m\n",
      "\u001b[34mAttempting uninstall: datasets\u001b[0m\n",
      "\u001b[34mFound existing installation: datasets 3.3.2\u001b[0m\n",
      "\u001b[34mUninstalling datasets-3.3.2:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled datasets-3.3.2\u001b[0m\n",
      "\u001b[34mSuccessfully installed datasets-4.0.0 gitdb-4.0.12 gitpython-3.1.45 sentry-sdk-2.34.1 smmap-5.0.2 wandb-0.21.1\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip is available: 25.1.1 -> 25.2\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m2025-08-12 17:42:31,193 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2025-08-12 17:42:31,193 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2025-08-12 17:42:31,234 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-08-12 17:42:31,262 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-08-12 17:42:31,289 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-08-12 17:42:31,299 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"dataset\": \"/opt/ml/input/data/dataset\",\n",
      "        \"model\": \"/opt/ml/input/data/model\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.4xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"alpha\": 0.7,\n",
      "        \"epochs\": 1,\n",
      "        \"eval_batch_size\": 2,\n",
      "        \"eval_steps\": 50,\n",
      "        \"gradient_accumulation_steps\": 8,\n",
      "        \"learning_rate\": 0.0002,\n",
      "        \"logging_steps\": 10,\n",
      "        \"lora_alpha\": 32,\n",
      "        \"lora_dropout\": 0.05,\n",
      "        \"lora_r\": 16,\n",
      "        \"lr_scheduler_type\": \"cosine\",\n",
      "        \"optim\": \"paged_adamw_8bit\",\n",
      "        \"save_steps\": 50,\n",
      "        \"train_batch_size\": 2,\n",
      "        \"weight_decay\": 0.01\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"dataset\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"model\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.4xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": true,\n",
      "    \"job_name\": \"huggingface-pytorch-training-2025-08-12-17-37-00-151\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://self-corrective-llm-data/huggingface-pytorch-training-2025-08-12-17-37-00-151/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.4xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.4xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\",\n",
      "        \"topology\": null\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"alpha\":0.7,\"epochs\":1,\"eval_batch_size\":2,\"eval_steps\":50,\"gradient_accumulation_steps\":8,\"learning_rate\":0.0002,\"logging_steps\":10,\"lora_alpha\":32,\"lora_dropout\":0.05,\"lora_r\":16,\"lr_scheduler_type\":\"cosine\",\"optim\":\"paged_adamw_8bit\",\"save_steps\":50,\"train_batch_size\":2,\"weight_decay\":0.01}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.4xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.4xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"dataset\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"model\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"dataset\",\"model\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g5.4xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.4xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=16\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://self-corrective-llm-data/huggingface-pytorch-training-2025-08-12-17-37-00-151/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"dataset\":\"/opt/ml/input/data/dataset\",\"model\":\"/opt/ml/input/data/model\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g5.4xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"alpha\":0.7,\"epochs\":1,\"eval_batch_size\":2,\"eval_steps\":50,\"gradient_accumulation_steps\":8,\"learning_rate\":0.0002,\"logging_steps\":10,\"lora_alpha\":32,\"lora_dropout\":0.05,\"lora_r\":16,\"lr_scheduler_type\":\"cosine\",\"optim\":\"paged_adamw_8bit\",\"save_steps\":50,\"train_batch_size\":2,\"weight_decay\":0.01},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"dataset\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"model\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.4xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":true,\"job_name\":\"huggingface-pytorch-training-2025-08-12-17-37-00-151\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://self-corrective-llm-data/huggingface-pytorch-training-2025-08-12-17-37-00-151/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":16,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.4xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.4xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--alpha\",\"0.7\",\"--epochs\",\"1\",\"--eval_batch_size\",\"2\",\"--eval_steps\",\"50\",\"--gradient_accumulation_steps\",\"8\",\"--learning_rate\",\"0.0002\",\"--logging_steps\",\"10\",\"--lora_alpha\",\"32\",\"--lora_dropout\",\"0.05\",\"--lora_r\",\"16\",\"--lr_scheduler_type\",\"cosine\",\"--optim\",\"paged_adamw_8bit\",\"--save_steps\",\"50\",\"--train_batch_size\",\"2\",\"--weight_decay\",\"0.01\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_DATASET=/opt/ml/input/data/dataset\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_MODEL=/opt/ml/input/data/model\u001b[0m\n",
      "\u001b[34mSM_HP_ALPHA=0.7\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=1\u001b[0m\n",
      "\u001b[34mSM_HP_EVAL_BATCH_SIZE=2\u001b[0m\n",
      "\u001b[34mSM_HP_EVAL_STEPS=50\u001b[0m\n",
      "\u001b[34mSM_HP_GRADIENT_ACCUMULATION_STEPS=8\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=0.0002\u001b[0m\n",
      "\u001b[34mSM_HP_LOGGING_STEPS=10\u001b[0m\n",
      "\u001b[34mSM_HP_LORA_ALPHA=32\u001b[0m\n",
      "\u001b[34mSM_HP_LORA_DROPOUT=0.05\u001b[0m\n",
      "\u001b[34mSM_HP_LORA_R=16\u001b[0m\n",
      "\u001b[34mSM_HP_LR_SCHEDULER_TYPE=cosine\u001b[0m\n",
      "\u001b[34mSM_HP_OPTIM=paged_adamw_8bit\u001b[0m\n",
      "\u001b[34mSM_HP_SAVE_STEPS=50\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN_BATCH_SIZE=2\u001b[0m\n",
      "\u001b[34mSM_HP_WEIGHT_DECAY=0.01\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python311.zip:/opt/conda/lib/python3.11:/opt/conda/lib/python3.11/lib-dynload:/opt/conda/lib/python3.11/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.11 train.py --alpha 0.7 --epochs 1 --eval_batch_size 2 --eval_steps 50 --gradient_accumulation_steps 8 --learning_rate 0.0002 --logging_steps 10 --lora_alpha 32 --lora_dropout 0.05 --lora_r 16 --lr_scheduler_type cosine --optim paged_adamw_8bit --save_steps 50 --train_batch_size 2 --weight_decay 0.01\u001b[0m\n",
      "\u001b[34m2025-08-12 17:42:31,300 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\u001b[0m\n",
      "\u001b[34m2025-08-12 17:42:31,300 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34m--- Loading tokenizer ---\u001b[0m\n",
      "\u001b[34m--- Loading BNB Config ---\u001b[0m\n",
      "\u001b[34m--- Loading Model with BNB Config ---\u001b[0m\n",
      "\u001b[34m`low_cpu_mem_usage` was None, now default to True since model is quantized.\u001b[0m\n",
      "\u001b[34m`low_cpu_mem_usage` was None, now default to True since model is quantized.\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:05,  1.95s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  50%|█████     | 2/4 [00:03<00:03,  1.89s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  75%|███████▌  | 3/4 [00:05<00:01,  1.86s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 4/4 [00:06<00:00,  1.38s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 4/4 [00:06<00:00,  1.57s/it]\u001b[0m\n",
      "\u001b[34m--- Prepare model for kbit training ---\u001b[0m\n",
      "\u001b[34m--- Configuring PEFT ---\u001b[0m\n",
      "\u001b[34m--- Applying PEFT ---\u001b[0m\n",
      "\u001b[34mtrainable params: 567,296,001 || all params: 8,597,585,922 || trainable%: 6.5983\u001b[0m\n",
      "\u001b[34m--- Loading dataset ---\u001b[0m\n",
      "\u001b[34mDatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels', 'hallucination_labels'],\n",
      "        num_rows: 42049\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels', 'hallucination_labels'],\n",
      "        num_rows: 4673\n",
      "    })\u001b[0m\n",
      "\u001b[34m})\u001b[0m\n",
      "\u001b[34m--- Setting up Trainer ---\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/opt/ml/code/src/trainer.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `SelfCorrectionTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\u001b[0m\n",
      "\u001b[34mNo label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\u001b[0m\n",
      "\u001b[34mNo label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\u001b[0m\n",
      "\u001b[34m--- Starting training ---\u001b[0m\n",
      "\u001b[34mwandb: WARNING The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\u001b[0m\n",
      "\u001b[34mwandb: Currently logged in as: kyrylldekanenko (kyrylldekanenko-) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\u001b[0m\n",
      "\u001b[34mwandb: Tracking run with wandb version 0.21.1\u001b[0m\n",
      "\u001b[34mwandb: Run data is saved locally in /opt/ml/code/wandb/run-20250812_174244-huggingface-pytorch-training-2025-08-12-17-37-00-151-6vpplz-algo-1\u001b[0m\n",
      "\u001b[34mwandb: Run `wandb offline` to turn off syncing.\u001b[0m\n",
      "\u001b[34mwandb: Syncing run /opt/ml/model\u001b[0m\n",
      "\u001b[34mwandb: ⭐️ View project at https://wandb.ai/kyrylldekanenko-/huggingface\u001b[0m\n",
      "\u001b[34mwandb: 🚀 View run at https://wandb.ai/kyrylldekanenko-/huggingface/runs/huggingface-pytorch-training-2025-08-12-17-37-00-151-6vpplz-algo-1\u001b[0m\n",
      "\u001b[34m0%|          | 0/2628 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mYou're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\u001b[0m\n",
      "\u001b[34mYou're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\u001b[0m\n",
      "\u001b[34m`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\u001b[0m\n",
      "\u001b[34m`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\u001b[0m\n",
      "\u001b[34m{'token_loss': 2.285245656967163, 'hallucination_loss': 0.6026466488838196, 'epoch': 0}\u001b[0m\n",
      "\u001b[34m0%|          | 0/2628 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m{'token_loss': 2.5491507053375244, 'hallucination_loss': 0.7236279845237732, 'epoch': 0}\u001b[0m\n",
      "\u001b[34m0%|          | 0/2628 [00:02<?, ?it/s]\u001b[0m\n",
      "\u001b[34m{'token_loss': 2.624701499938965, 'hallucination_loss': 0.6540066003799438, 'epoch': 0}\u001b[0m\n",
      "\u001b[34m0%|          | 0/2628 [00:04<?, ?it/s]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.6048741936683655, 'hallucination_loss': 0.8205106258392334, 'epoch': 0}\u001b[0m\n",
      "\u001b[34m0%|          | 0/2628 [00:06<?, ?it/s]\u001b[0m\n",
      "\u001b[34m{'token_loss': 1.4993427991867065, 'hallucination_loss': 0.4337505102157593, 'epoch': 0}\u001b[0m\n",
      "\u001b[34m0%|          | 0/2628 [00:09<?, ?it/s]\u001b[0m\n",
      "\u001b[34m{'token_loss': 2.0731723308563232, 'hallucination_loss': 0.6937856674194336, 'epoch': 0}\u001b[0m\n",
      "\u001b[34m0%|          | 0/2628 [00:11<?, ?it/s]\u001b[0m\n",
      "\u001b[34m{'token_loss': 3.67818546295166, 'hallucination_loss': 0.7913889288902283, 'epoch': 0}\u001b[0m\n",
      "\u001b[34m0%|          | 0/2628 [00:12<?, ?it/s]\u001b[0m\n",
      "\u001b[34m{'token_loss': 2.382960557937622, 'hallucination_loss': 0.5415369272232056, 'epoch': 0}\u001b[0m\n",
      "\u001b[34m0%|          | 0/2628 [00:14<?, ?it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 1/2628 [00:15<11:30:46, 15.78s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.6202755570411682, 'hallucination_loss': 0.3957706093788147, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 1/2628 [00:16<11:30:46, 15.78s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.6549022197723389, 'hallucination_loss': 0.45900410413742065, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 1/2628 [00:18<11:30:46, 15.78s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 3.0505118370056152, 'hallucination_loss': 0.37847578525543213, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 1/2628 [00:20<11:30:46, 15.78s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.7103272080421448, 'hallucination_loss': 0.41973283886909485, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 1/2628 [00:21<11:30:46, 15.78s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 1.1192731857299805, 'hallucination_loss': 0.27482593059539795, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 1/2628 [00:23<11:30:46, 15.78s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 2.0338499546051025, 'hallucination_loss': 0.47033926844596863, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 1/2628 [00:25<11:30:46, 15.78s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.6390222311019897, 'hallucination_loss': 0.33592039346694946, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 1/2628 [00:27<11:30:46, 15.78s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 1.86948561668396, 'hallucination_loss': 0.22730734944343567, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 1/2628 [00:29<11:30:46, 15.78s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 2/2628 [00:30<10:59:01, 15.06s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.8341293334960938, 'hallucination_loss': 0.09968294203281403, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 2/2628 [00:30<10:59:01, 15.06s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 1.4759401082992554, 'hallucination_loss': 0.25656476616859436, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 2/2628 [00:32<10:59:01, 15.06s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.3194461166858673, 'hallucination_loss': 0.07284125685691833, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 2/2628 [00:34<10:59:01, 15.06s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 1.0656794309616089, 'hallucination_loss': 0.10725492238998413, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 2/2628 [00:37<10:59:01, 15.06s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.9470041990280151, 'hallucination_loss': 0.07996851950883865, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 2/2628 [00:39<10:59:01, 15.06s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 1.320194125175476, 'hallucination_loss': 0.15040722489356995, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 2/2628 [00:41<10:59:01, 15.06s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.8280677795410156, 'hallucination_loss': 0.11912497878074646, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 2/2628 [00:43<10:59:01, 15.06s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.38359183073043823, 'hallucination_loss': 0.08983475714921951, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 2/2628 [00:45<10:59:01, 15.06s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 3/2628 [00:47<11:46:46, 16.15s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 1.1322869062423706, 'hallucination_loss': 0.1398124098777771, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 3/2628 [00:48<11:46:46, 16.15s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.573481559753418, 'hallucination_loss': 0.044670283794403076, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 3/2628 [00:49<11:46:46, 16.15s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.4953727126121521, 'hallucination_loss': 0.04715580865740776, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 3/2628 [00:51<11:46:46, 16.15s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 1.250397801399231, 'hallucination_loss': 0.14525896310806274, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 3/2628 [00:53<11:46:46, 16.15s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.7428267002105713, 'hallucination_loss': 0.09276538342237473, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 3/2628 [00:54<11:46:46, 16.15s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.684513509273529, 'hallucination_loss': 0.02509559690952301, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 3/2628 [00:56<11:46:46, 16.15s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 1.204270601272583, 'hallucination_loss': 0.17690128087997437, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 3/2628 [00:58<11:46:46, 16.15s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 1.9469705820083618, 'hallucination_loss': 0.0886092334985733, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 3/2628 [01:00<11:46:46, 16.15s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 4/2628 [01:01<11:11:32, 15.36s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.6034313440322876, 'hallucination_loss': 0.09303447604179382, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 4/2628 [01:02<11:11:32, 15.36s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 1.4486234188079834, 'hallucination_loss': 0.6810522675514221, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 4/2628 [01:04<11:11:32, 15.36s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.3526385724544525, 'hallucination_loss': 0.3046679198741913, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 4/2628 [01:06<11:11:32, 15.36s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.395352840423584, 'hallucination_loss': 0.12295030802488327, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 4/2628 [01:08<11:11:32, 15.36s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 1.0930842161178589, 'hallucination_loss': 0.35371723771095276, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 4/2628 [01:10<11:11:32, 15.36s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 1.1020278930664062, 'hallucination_loss': 0.5866333842277527, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 4/2628 [01:11<11:11:32, 15.36s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 2.0411276817321777, 'hallucination_loss': 1.115060806274414, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 4/2628 [01:13<11:11:32, 15.36s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.28082188963890076, 'hallucination_loss': 0.3553448021411896, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 4/2628 [01:14<11:11:32, 15.36s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 5/2628 [01:16<10:56:27, 15.02s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 1.6916773319244385, 'hallucination_loss': 0.44975364208221436, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 5/2628 [01:16<10:56:27, 15.02s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.6435385346412659, 'hallucination_loss': 0.017324913293123245, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 5/2628 [01:18<10:56:27, 15.02s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 1.0349732637405396, 'hallucination_loss': 0.10126892477273941, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 5/2628 [01:21<10:56:27, 15.02s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 1.1819591522216797, 'hallucination_loss': 0.1845790147781372, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 5/2628 [01:22<10:56:27, 15.02s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.5837641358375549, 'hallucination_loss': 0.1775282472372055, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 5/2628 [01:24<10:56:27, 15.02s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.5677205324172974, 'hallucination_loss': 0.017574016004800797, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 5/2628 [01:26<10:56:27, 15.02s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.5006396174430847, 'hallucination_loss': 0.045940645039081573, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 5/2628 [01:28<10:56:27, 15.02s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 1.0714908838272095, 'hallucination_loss': 0.25269025564193726, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 5/2628 [01:30<10:56:27, 15.02s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 6/2628 [01:32<11:05:53, 15.24s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.5562616586685181, 'hallucination_loss': 0.028793901205062866, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 6/2628 [01:32<11:05:53, 15.24s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.6221256852149963, 'hallucination_loss': 0.021205054596066475, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 6/2628 [01:35<11:05:53, 15.24s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.5705644488334656, 'hallucination_loss': 0.023105544969439507, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 6/2628 [01:36<11:05:53, 15.24s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.7031342387199402, 'hallucination_loss': 0.13254289329051971, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 6/2628 [01:38<11:05:53, 15.24s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.3762355148792267, 'hallucination_loss': 0.015761999413371086, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 6/2628 [01:40<11:05:53, 15.24s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.2448233962059021, 'hallucination_loss': 0.008499392308294773, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 6/2628 [01:42<11:05:53, 15.24s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.9490052461624146, 'hallucination_loss': 0.0200788713991642, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 6/2628 [01:43<11:05:53, 15.24s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.6405646800994873, 'hallucination_loss': 0.09792327880859375, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 6/2628 [01:45<11:05:53, 15.24s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 7/2628 [01:46<10:56:13, 15.02s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.4595422148704529, 'hallucination_loss': 0.013761257752776146, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 7/2628 [01:47<10:56:13, 15.02s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.545407235622406, 'hallucination_loss': 0.019784867763519287, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 7/2628 [01:50<10:56:13, 15.02s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.32790231704711914, 'hallucination_loss': 0.06897139549255371, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 7/2628 [01:52<10:56:13, 15.02s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.5899526476860046, 'hallucination_loss': 0.12937869131565094, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 7/2628 [01:53<10:56:13, 15.02s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.31112056970596313, 'hallucination_loss': 0.010019805282354355, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 7/2628 [01:55<10:56:13, 15.02s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.5576337575912476, 'hallucination_loss': 0.00811781082302332, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 7/2628 [01:57<10:56:13, 15.02s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 1.6083091497421265, 'hallucination_loss': 0.26132339239120483, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 7/2628 [01:59<10:56:13, 15.02s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 2.1962625980377197, 'hallucination_loss': 0.5068759918212891, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 7/2628 [02:01<10:56:13, 15.02s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 8/2628 [02:02<11:02:01, 15.16s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.9137260317802429, 'hallucination_loss': 0.206039160490036, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 8/2628 [02:02<11:02:01, 15.16s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.34902223944664, 'hallucination_loss': 0.025927437469363213, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 8/2628 [02:04<11:02:01, 15.16s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.2469109296798706, 'hallucination_loss': 0.023063594475388527, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 8/2628 [02:06<11:02:01, 15.16s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.3527207374572754, 'hallucination_loss': 0.03963584080338478, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 8/2628 [02:07<11:02:01, 15.16s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.4803236126899719, 'hallucination_loss': 0.0192505344748497, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 8/2628 [02:10<11:02:01, 15.16s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.48935529589653015, 'hallucination_loss': 0.03962403163313866, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 8/2628 [02:12<11:02:01, 15.16s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 1.4727839231491089, 'hallucination_loss': 0.04261835291981697, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 8/2628 [02:14<11:02:01, 15.16s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.5704404711723328, 'hallucination_loss': 0.038041893392801285, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 8/2628 [02:16<11:02:01, 15.16s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 9/2628 [02:17<11:01:43, 15.16s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.3145652115345001, 'hallucination_loss': 0.018852178007364273, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 9/2628 [02:17<11:01:43, 15.16s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.16783693432807922, 'hallucination_loss': 0.02096734754741192, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 9/2628 [02:19<11:01:43, 15.16s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.4094160497188568, 'hallucination_loss': 0.014355839230120182, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 9/2628 [02:21<11:01:43, 15.16s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.4979737102985382, 'hallucination_loss': 0.021175168454647064, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 9/2628 [02:23<11:01:43, 15.16s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.920700192451477, 'hallucination_loss': 0.10726015269756317, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 9/2628 [02:26<11:01:43, 15.16s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.4777522087097168, 'hallucination_loss': 0.025702260434627533, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 9/2628 [02:28<11:01:43, 15.16s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.7832269072532654, 'hallucination_loss': 0.11971202492713928, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 9/2628 [02:29<11:01:43, 15.16s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.5139430165290833, 'hallucination_loss': 0.11398696899414062, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 9/2628 [02:31<11:01:43, 15.16s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 10/2628 [02:32<11:07:17, 15.29s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 6.0006, 'grad_norm': 22.521936416625977, 'learning_rate': 0.00019999285480877798, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 10/2628 [02:32<11:07:17, 15.29s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.8721837401390076, 'hallucination_loss': 0.23186680674552917, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 10/2628 [02:33<11:07:17, 15.29s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.6747179627418518, 'hallucination_loss': 0.09430798143148422, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 10/2628 [02:35<11:07:17, 15.29s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.15127281844615936, 'hallucination_loss': 0.04695522040128708, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 10/2628 [02:37<11:07:17, 15.29s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.46624428033828735, 'hallucination_loss': 0.11536990106105804, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 10/2628 [02:39<11:07:17, 15.29s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.6030381917953491, 'hallucination_loss': 0.14379414916038513, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 10/2628 [02:41<11:07:17, 15.29s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.6405970454216003, 'hallucination_loss': 0.18387649953365326, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 10/2628 [02:42<11:07:17, 15.29s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.3853210210800171, 'hallucination_loss': 0.041890036314725876, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 10/2628 [02:44<11:07:17, 15.29s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.8460659980773926, 'hallucination_loss': 0.13409501314163208, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 10/2628 [02:46<11:07:17, 15.29s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 11/2628 [02:47<11:00:48, 15.15s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.8333802223205566, 'hallucination_loss': 0.18479187786579132, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 11/2628 [02:48<11:00:48, 15.15s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.452750563621521, 'hallucination_loss': 0.025175118818879128, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 11/2628 [02:50<11:00:48, 15.15s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 1.5501946210861206, 'hallucination_loss': 0.1757570207118988, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 11/2628 [02:52<11:00:48, 15.15s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.7927806377410889, 'hallucination_loss': 0.08109717816114426, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 11/2628 [02:53<11:00:48, 15.15s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.279592901468277, 'hallucination_loss': 0.04500051960349083, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 11/2628 [02:55<11:00:48, 15.15s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.4244677722454071, 'hallucination_loss': 0.05424770340323448, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 11/2628 [02:57<11:00:48, 15.15s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 1.2924681901931763, 'hallucination_loss': 0.24522940814495087, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 11/2628 [02:58<11:00:48, 15.15s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.5608307123184204, 'hallucination_loss': 0.07573005557060242, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 11/2628 [03:00<11:00:48, 15.15s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 12/2628 [03:01<10:49:42, 14.90s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 2.413304328918457, 'hallucination_loss': 0.43607062101364136, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 12/2628 [03:02<10:49:42, 14.90s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 1.0782040357589722, 'hallucination_loss': 0.045050427317619324, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 12/2628 [03:04<10:49:42, 14.90s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.48494571447372437, 'hallucination_loss': 0.08798340708017349, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 12/2628 [03:06<10:49:42, 14.90s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.5385732650756836, 'hallucination_loss': 0.08025721460580826, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 12/2628 [03:07<10:49:42, 14.90s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 0.4333243668079376, 'hallucination_loss': 0.14674828946590424, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 12/2628 [03:09<10:49:42, 14.90s/it]\u001b[0m\n",
      "\u001b[34m{'token_loss': 1.4836411476135254, 'hallucination_loss': 0.1284288913011551, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 12/2628 [03:10<10:49:42, 14.90s/it]\u001b[0m\n",
      "SageMaker training job started.\n"
     ]
    }
   ],
   "source": [
    "# --- Start Training ---\n",
    "huggingface_estimator.fit({\n",
    "    \"dataset\": dataset_s3_uri,\n",
    "    \"model\": base_model_s3_uri\n",
    "})\n",
    "\n",
    "print(\"SageMaker training job started.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c3757f-e646-4ecf-b536-b156f7b223f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
