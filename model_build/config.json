{
    "model_id": "meta-llama/Llama-3.2-1B-Instruct",
    "local_model_dir": "model",
    "s3_bucket": "self-corrective-llm-data",
    "s3_key_prefix": "initial_model",
    "inference_script_name": "inference.py",
    "tarball_name": "model.tar.gz"
} 